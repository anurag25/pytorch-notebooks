{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Copy of tensor_tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anurag25/pytorch-notebooks/blob/master/Deep%20Learning%20with%20PyTorch%20A%2060%20Minute%20Blitz/1_Copy_of_tensor_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fquPKElAHzPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQZ97dYwHzPl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "What is PyTorch?\n",
        "================\n",
        "\n",
        "It’s a Python-based scientific computing package targeted at two sets of\n",
        "audiences:\n",
        "\n",
        "-  A replacement for NumPy to use the power of GPUs\n",
        "-  a deep learning research platform that provides maximum flexibility\n",
        "   and speed\n",
        "\n",
        "Getting Started\n",
        "---------------\n",
        "\n",
        "Tensors\n",
        "^^^^^^^\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, with the addition being that\n",
        "Tensors can also be used on a GPU to accelerate computing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2iPGij8KDJV",
        "colab_type": "text"
      },
      "source": [
        "# [My Block 0] Python's `__future__` Module\n",
        "\n",
        "\n",
        "[Official Documentation](https://docs.python.org/3/reference/simple_stmts.html#future-statements): <br />\n",
        "A future statement is a directive to the compiler that a particular module should be compiled using syntax or semantics that will be available in a specified future release of Python where the feature becomes standard.\n",
        "\n",
        "The future statement is intended to ease migration to future versions of Python that introduce incompatible changes to the language. It allows use of the new features on a per-module basis before the release in which the feature becomes standard.\n",
        "\n",
        "The only feature in Python 3.7 that requires using the future statement is `annotations`.\n",
        "\n",
        "All historical features enabled by the future statement are still recognized by Python 3. The list includes `absolute_import, division`, `generators`, `generator_stop`, `unicode_literals`, `print_function`, `nested_scopes` and `with_statement`. They are all redundant because they are always enabled, and only kept for backwards compatibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYOd66AnNPPG",
        "colab_type": "code",
        "outputId": "0a2962db-08bf-4c56-a77d-d37ce83090f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9 (default, Apr 18 2020, 01:56:04) \n",
            "[GCC 8.4.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEUf3yhiNGPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [My Block 0 End]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nUfTsmyHzPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8YjtA5PHzQB",
        "colab_type": "text"
      },
      "source": [
        "Construct a 5x3 matrix, uninitialized:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOXAsqF8HzQH",
        "colab_type": "code",
        "outputId": "8356f41f-018d-49cb-fbae-f419feced696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "x = torch.empty(5, 3)\n",
        "# A bolck of memory allocated for x which will contain uninitialized data\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[9.4715e-36, 0.0000e+00, 1.5975e-43],\n",
            "        [1.3873e-43, 1.4574e-43, 6.4460e-44],\n",
            "        [1.5975e-43, 1.3593e-43, 1.5414e-43],\n",
            "        [1.4013e-43, 1.5414e-43, 2.5591e-41],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4NfBhmGR5sp",
        "colab_type": "code",
        "outputId": "276b165f-93cd-46e9-e242-cd1e49415653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "help(torch.empty)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on built-in function empty:\n",
            "\n",
            "empty(...)\n",
            "    empty(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
            "    \n",
            "    Returns a tensor filled with uninitialized data. The shape of the tensor is\n",
            "    defined by the variable argument :attr:`size`.\n",
            "    \n",
            "    Args:\n",
            "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
            "            Can be a variable number of arguments or a collection like a list or tuple.\n",
            "        out (Tensor, optional): the output tensor.\n",
            "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
            "            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
            "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
            "            Default: ``torch.strided``.\n",
            "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
            "            Default: if ``None``, uses the current device for the default tensor type\n",
            "            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
            "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
            "        requires_grad (bool, optional): If autograd should record operations on the\n",
            "            returned tensor. Default: ``False``.\n",
            "        pin_memory (bool, optional): If set, returned tensor would be allocated in\n",
            "            the pinned memory. Works only for CPU tensors. Default: ``False``.\n",
            "        memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
            "            returned Tensor. Default: ``torch.contiguous_format``.\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        >>> torch.empty(2, 3)\n",
            "        tensor(1.00000e-08 *\n",
            "               [[ 6.3984,  0.0000,  0.0000],\n",
            "                [ 0.0000,  0.0000,  0.0000]])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tA8C9G-SKEn",
        "colab_type": "code",
        "outputId": "92fbb022-6fad-4b4c-9fb9-6d6fc5f81e7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "torch.empty(2, 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6.0359e-36, 0.0000e+00, 1.5975e-43],\n",
              "        [1.3873e-43, 1.4574e-43, 6.4460e-44]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o_gksPdHzQX",
        "colab_type": "text"
      },
      "source": [
        "Construct a randomly initialized matrix:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtBWm9i-S2Dk",
        "colab_type": "code",
        "outputId": "6d279744-bac1-4224-8831-430ede531579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "source": [
        "help(torch.rand)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on built-in function rand:\n",
            "\n",
            "rand(...)\n",
            "    rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
            "    \n",
            "    Returns a tensor filled with random numbers from a uniform distribution\n",
            "    on the interval :math:`[0, 1)`\n",
            "    \n",
            "    The shape of the tensor is defined by the variable argument :attr:`size`.\n",
            "    \n",
            "    Args:\n",
            "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
            "            Can be a variable number of arguments or a collection like a list or tuple.\n",
            "        out (Tensor, optional): the output tensor.\n",
            "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
            "            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
            "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
            "            Default: ``torch.strided``.\n",
            "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
            "            Default: if ``None``, uses the current device for the default tensor type\n",
            "            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
            "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
            "        requires_grad (bool, optional): If autograd should record operations on the\n",
            "            returned tensor. Default: ``False``.\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        >>> torch.rand(4)\n",
            "        tensor([ 0.5204,  0.2503,  0.3525,  0.5673])\n",
            "        >>> torch.rand(2, 3)\n",
            "        tensor([[ 0.8237,  0.5781,  0.6879],\n",
            "                [ 0.3816,  0.7249,  0.0998]])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH0BNMmmTTua",
        "colab_type": "code",
        "outputId": "6e875fbf-5c6a-41d6-9323-101ee7313795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "x = torch.rand(4)\n",
        "print(x)\n",
        "print(x.shape)\n",
        "print(type(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.8825, 0.3960, 0.0035, 0.2524])\n",
            "torch.Size([4])\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkVWCB_9HzQZ",
        "colab_type": "code",
        "outputId": "29c7f598-c067-4491-f258-976a71c9a977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "# random numbers between [0, 1) from uniform distribution\n",
        "print(x)\n",
        "print(x.shape)\n",
        "print(type(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9853, 0.5394, 0.6494],\n",
            "        [0.8340, 0.5207, 0.7737],\n",
            "        [0.1691, 0.4988, 0.1855],\n",
            "        [0.9557, 0.8262, 0.9122],\n",
            "        [0.2325, 0.5099, 0.8710]])\n",
            "torch.Size([5, 3])\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRQ4_HCvHzQp",
        "colab_type": "text"
      },
      "source": [
        "Construct a matrix filled zeros and of dtype long:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-ZsrLijTk4f",
        "colab_type": "code",
        "outputId": "62013cef-01b2-4367-cfc6-81052da7aeb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "torch.long"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78RKbtjfUSLb",
        "colab_type": "code",
        "outputId": "b894193a-126e-413e-ddb6-a47a944db918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "x = torch.zeros(5)\n",
        "print(type(x))\n",
        "print(x.type())\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.FloatTensor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl7eQq5YHzQr",
        "colab_type": "code",
        "outputId": "276c6fc6-6ecc-4691-dfac-a9d60799ac91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "# torch.Tensor is an alias for the default tensor type (torch.FloatTensor)\n",
        "# So if dtype not give, float tensor will be created. See the cell just above\n",
        "print(type(x))\n",
        "print(x.type())\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.LongTensor\n",
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G27z4gbwHzQ7",
        "colab_type": "text"
      },
      "source": [
        "Construct a tensor directly from data:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfNjufJacEyG",
        "colab_type": "code",
        "outputId": "bacb6dd8-56db-437b-97a2-92b35fd851ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# returns the current default tensor type\n",
        "torch.get_default_dtype()\n",
        "\n",
        "# Use torch.set_default_tensor_type(t) to set the default to type t"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fpHVCRQcne_",
        "colab_type": "code",
        "outputId": "cc95e8ed-1686-4405-9428-a3829444c6c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "# numel: Returns the total number of elements in the input tensor.\n",
        "\n",
        "print(torch.numel(torch.zeros(4,4)))\n",
        "torch.zeros(4, 4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOdDcwU6HzQ9",
        "colab_type": "code",
        "outputId": "b11ef878-7902-4a47-fe84-85bfd28c344a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "# torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False) → Tensor\n",
        "# data (array_like) – Initial data for the tensor. Can be a list, tuple, NumPy ndarray, scalar, and other types.\n",
        "# requires_grad (bool, optional) – If autograd should record operations on the returned tensor.\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(type(x))\n",
        "print(x.type())\n",
        "print(x)\n",
        "'''\n",
        "torch.tensor() always copies data. \n",
        "If you have a Tensor data and want to avoid a copy, use torch.Tensor.requires_grad_() or torch.Tensor.detach(). \n",
        "If you have a NumPy ndarray and want to avoid a copy, use torch.as_tensor().\n",
        "'''\n",
        "print(x.size())\n",
        "print(x.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.FloatTensor\n",
            "tensor([5.5000, 3.0000])\n",
            "torch.Size([2])\n",
            "torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPE9acvdHzRM",
        "colab_type": "text"
      },
      "source": [
        "or create a tensor based on an existing tensor. These methods\n",
        "will reuse properties of the input tensor, e.g. dtype, unless\n",
        "new values are provided by user\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWguQfdlejeA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3b5e770f-d90a-458e-9c3a-59bbd1c4ef11"
      },
      "source": [
        "x"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.5000, 3.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g-Fa0kjHzRO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "61ae66be-542b-4e4a-a235-bbfbc4898016"
      },
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "# randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
        "#    Returns a tensor filled with random numbers from a normal distribution\n",
        "#    with mean `0` and variance `1` (also called the standard normal\n",
        "#    distribution).\n",
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "print(x)                                      # result has the same size"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[-0.8103, -0.8533, -0.6301],\n",
            "        [-0.7020, -0.5650, -0.4315],\n",
            "        [-0.1037, -0.3360,  1.4869],\n",
            "        [ 1.2886, -0.6033,  0.1010],\n",
            "        [-2.0664, -1.2248, -1.9221]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbvg13MNHzRZ",
        "colab_type": "text"
      },
      "source": [
        "Get its size:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXFdDx0zHzRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b5d53acd-6199-4d9c-8450-0580800f83aa"
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuPcZfdKHzRy",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` is in fact a tuple, so it supports all tuple operations.</p></div>\n",
        "\n",
        "Operations\n",
        "^^^^^^^^^^\n",
        "There are multiple syntaxes for operations. In the following\n",
        "example, we will take a look at the addition operation.\n",
        "\n",
        "Addition: syntax 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpB0llqlHzR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "1b7a8911-8f1d-4009-9642-b07e5c7f9dfa"
      },
      "source": [
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3244, -0.6619, -0.4794],\n",
            "        [-0.2512, -0.0628,  0.2300],\n",
            "        [ 0.0418,  0.4390,  2.0428],\n",
            "        [ 1.9776,  0.2906,  0.9795],\n",
            "        [-1.5978, -0.3911, -1.4398]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSjVUjcmHzR_",
        "colab_type": "text"
      },
      "source": [
        "Addition: syntax 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sho0co39fcfP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3056a058-1cf2-4a78-8882-f0eb2eb90cb2"
      },
      "source": [
        "help(torch.add)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on built-in function add:\n",
            "\n",
            "add(...)\n",
            "    .. function:: add(input, other, out=None)\n",
            "    \n",
            "    Adds the scalar :attr:`other` to each element of the input :attr:`input`\n",
            "    and returns a new resulting tensor.\n",
            "    \n",
            "    .. math::\n",
            "        \\text{out} = \\text{input} + \\text{other}\n",
            "    \n",
            "    If :attr:`input` is of type FloatTensor or DoubleTensor, :attr:`other` must be\n",
            "    a real number, otherwise it should be an integer.\n",
            "    \n",
            "    Args:\n",
            "        input (Tensor): the input tensor.\n",
            "        value (Number): the number to be added to each element of :attr:`input`\n",
            "    \n",
            "    Keyword arguments:\n",
            "        out (Tensor, optional): the output tensor.\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        >>> a = torch.randn(4)\n",
            "        >>> a\n",
            "        tensor([ 0.0202,  1.0985,  1.3506, -0.6056])\n",
            "        >>> torch.add(a, 20)\n",
            "        tensor([ 20.0202,  21.0985,  21.3506,  19.3944])\n",
            "    \n",
            "    .. function:: add(input, other, *, alpha=1, out=None)\n",
            "    \n",
            "    Each element of the tensor :attr:`other` is multiplied by the scalar\n",
            "    :attr:`alpha` and added to each element of the tensor :attr:`input`.\n",
            "    The resulting tensor is returned.\n",
            "    \n",
            "    The shapes of :attr:`input` and :attr:`other` must be\n",
            "    :ref:`broadcastable <broadcasting-semantics>`.\n",
            "    \n",
            "    .. math::\n",
            "        \\text{out} = \\text{input} + \\text{alpha} \\times \\text{other}\n",
            "    \n",
            "    If :attr:`other` is of type FloatTensor or DoubleTensor, :attr:`alpha` must be\n",
            "    a real number, otherwise it should be an integer.\n",
            "    \n",
            "    Args:\n",
            "        input (Tensor): the first input tensor\n",
            "        other (Tensor): the second input tensor\n",
            "        alpha (Number): the scalar multiplier for :attr:`other`\n",
            "    \n",
            "    Keyword arguments:\n",
            "        out (Tensor, optional): the output tensor.\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        >>> a = torch.randn(4)\n",
            "        >>> a\n",
            "        tensor([-0.9732, -0.3497,  0.6245,  0.4022])\n",
            "        >>> b = torch.randn(4, 1)\n",
            "        >>> b\n",
            "        tensor([[ 0.3743],\n",
            "                [-1.7724],\n",
            "                [-0.5811],\n",
            "                [-0.8017]])\n",
            "        >>> torch.add(a, b, alpha=10)\n",
            "        tensor([[  2.7695,   3.3930,   4.3672,   4.1450],\n",
            "                [-18.6971, -18.0736, -17.0994, -17.3216],\n",
            "                [ -6.7845,  -6.1610,  -5.1868,  -5.4090],\n",
            "                [ -8.9902,  -8.3667,  -7.3925,  -7.6147]])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkJQmEO5HzSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "add(input, other, out=None)\n",
        "    \n",
        "    Adds the scalar :attr:`other` to each element of the input :attr:`input`\n",
        "    and returns a new resulting tensor\n",
        "'''\n",
        "\n",
        "print(torch.add(x, y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xjmQbjsgVTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "02d23e03-d957-412e-ba79-ea3221b21864"
      },
      "source": [
        "# add(input, other, *, alpha=1, out=None)\n",
        "'''   \n",
        "    Each element of the tensor :attr:`other` is multiplied by the scalar\n",
        "    :attr:`alpha` and added to each element of the tensor :attr:`input`.\n",
        "    The resulting tensor is returned.\n",
        "\n",
        "'''\n",
        "a = torch.rand(4)\n",
        "print(a)\n",
        "b = torch.randn(4)\n",
        "print(b)\n",
        "print(torch.add(a, b, alpha = 1000))\n",
        "print(a + (b * 1000))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2023, 0.8727, 0.9498, 0.4153])\n",
            "tensor([-1.0726, -0.9525,  0.7217, -0.7835])\n",
            "tensor([-1072.3850,  -951.6572,   722.6768,  -783.0452])\n",
            "tensor([-1072.3851,  -951.6572,   722.6768,  -783.0452])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuQLOVegHzSO",
        "colab_type": "text"
      },
      "source": [
        "Addition: providing an output tensor as argument\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CebMaF9cHzSQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "1f7026eb-b4fa-40c2-d3c4-38f1123fd68f"
      },
      "source": [
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3244, -0.6619, -0.4794],\n",
            "        [-0.2512, -0.0628,  0.2300],\n",
            "        [ 0.0418,  0.4390,  2.0428],\n",
            "        [ 1.9776,  0.2906,  0.9795],\n",
            "        [-1.5978, -0.3911, -1.4398]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWR1cB3YHzSg",
        "colab_type": "text"
      },
      "source": [
        "Addition: in-place\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Puq_9o-HzSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "61406919-7d34-400f-e578-ed2ea165c917"
      },
      "source": [
        "# adds x to y\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3244, -0.6619, -0.4794],\n",
            "        [-0.2512, -0.0628,  0.2300],\n",
            "        [ 0.0418,  0.4390,  2.0428],\n",
            "        [ 1.9776,  0.2906,  0.9795],\n",
            "        [-1.5978, -0.3911, -1.4398]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51nklgw2HzSv",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n",
        "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n",
        "\n",
        "You can use standard NumPy-like indexing with all bells and whistles!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1dcjfYaHzSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b255c97f-9b65-4723-8505-5e6a30bc6df1"
      },
      "source": [
        "print(x[:, 1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.8533, -0.5650, -0.3360, -0.6033, -1.2248])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvHfMD7BHzS8",
        "colab_type": "text"
      },
      "source": [
        "Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jptcIP-mHzS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f3a3ed68-653c-4cab-faf6-fa3fa12eef7c"
      },
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwuYV0-UHzTG",
        "colab_type": "text"
      },
      "source": [
        "If you have a one element tensor, use ``.item()`` to get the value as a\n",
        "Python number\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq3sdbDzHzTJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "10b5665c-1378-467b-99a6-f660211acdba"
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.9269])\n",
            "1.9269232749938965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHayrRKvHzTS",
        "colab_type": "text"
      },
      "source": [
        "**Read later:**\n",
        "\n",
        "\n",
        "  100+ Tensor operations, including transposing, indexing, slicing,\n",
        "  mathematical operations, linear algebra, random numbers, etc.,\n",
        "  are described\n",
        "  `here <http://pytorch.org/docs/torch>`_.\n",
        "\n",
        "NumPy Bridge\n",
        "------------\n",
        "\n",
        "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
        "\n",
        "The Torch Tensor and NumPy array will share their underlying memory\n",
        "locations, and changing one will change the other.\n",
        "\n",
        "Converting a Torch Tensor to a NumPy Array\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnZdbMwPHzTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7b52f86b-f683-44b9-b212-7dbdaac4c160"
      },
      "source": [
        "a = torch.ones(5)\n",
        "print(a)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyRsohHpHzTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "35bfbad7-7aa7-41b2-adaa-f3de6d95aeed"
      },
      "source": [
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcBt9Q-ZHzTo",
        "colab_type": "text"
      },
      "source": [
        "See how the numpy array changed in value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQIbs43uHzTr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "943d6693-ceb2-41ad-c323-574cfbf603ee"
      },
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MptO5cPGHzT0",
        "colab_type": "text"
      },
      "source": [
        "Converting NumPy Array to Torch Tensor\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "See how changing the np array changed the Torch Tensor automatically\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siAM3ZVeHzT3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "15a365c9-7da6-4c1d-a3fe-542f4e9de770"
      },
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cXJQSkWHzUB",
        "colab_type": "text"
      },
      "source": [
        "All the Tensors on the CPU except a CharTensor support converting to\n",
        "NumPy and back.\n",
        "\n",
        "CUDA Tensors\n",
        "------------\n",
        "\n",
        "Tensors can be moved onto any device using the ``.to`` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfkd8434HzUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARYkRpuchwVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}