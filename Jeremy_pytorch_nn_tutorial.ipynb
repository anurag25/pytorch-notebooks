{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Jeremy_pytorch_nn_tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perceptronnn/pytorch-notebooks/blob/master/Jeremy_pytorch_nn_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl7sjZYVscFD",
        "colab_type": "text"
      },
      "source": [
        "[What is torch.nn really?](https://pytorch.org/tutorials/beginner/nn_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFV9U1ZuKp6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ejQCCQVKB5Y",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "What is `torch.nn` *really*?\n",
        "============================\n",
        "by Jeremy Howard, `fast.ai <https://www.fast.ai>`_. Thanks to Rachel Thomas and Francisco Ingham.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q7eQkfkKB5a",
        "colab_type": "text"
      },
      "source": [
        "We recommend running this tutorial as a notebook, not a script. To download the notebook (.ipynb) file,\n",
        "click the link at the top of the page.\n",
        "\n",
        "PyTorch provides the elegantly designed modules and classes `torch.nn <https://pytorch.org/docs/stable/nn.html>`_ ,\n",
        "`torch.optim <https://pytorch.org/docs/stable/optim.html>`_ ,\n",
        "`Dataset <https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset>`_ ,\n",
        "and `DataLoader <https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader>`_\n",
        "to help you create and train neural networks.\n",
        "In order to fully utilize their power and customize\n",
        "them for your problem, you need to really understand exactly what they're\n",
        "doing. To develop this understanding, we will first train basic neural net\n",
        "on the MNIST data set without using any features from these models; we will\n",
        "initially only use the most basic PyTorch tensor functionality. Then, we will\n",
        "incrementally add one feature from ``torch.nn``, ``torch.optim``, ``Dataset``, or\n",
        "``DataLoader`` at a time, showing exactly what each piece does, and how it\n",
        "works to make the code either more concise, or more flexible.\n",
        "\n",
        "**This tutorial assumes you already have PyTorch installed, and are familiar\n",
        "with the basics of tensor operations.** (If you're familiar with Numpy array\n",
        "operations, you'll find the PyTorch tensor operations used here nearly identical).\n",
        "\n",
        "MNIST data setup\n",
        "----------------\n",
        "\n",
        "We will use the classic `MNIST <http://deeplearning.net/data/mnist/>`_ dataset,\n",
        "which consists of black-and-white images of hand-drawn digits (between 0 and 9).\n",
        "\n",
        "We will use `pathlib <https://docs.python.org/3/library/pathlib.html>`_\n",
        "for dealing with paths (part of the Python 3 standard library), and will\n",
        "download the dataset using\n",
        "`requests <http://docs.python-requests.org/en/master/>`_. We will only\n",
        "import modules when we use them, so you can see exactly what's being\n",
        "used at each point.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA5A9DtvKu3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "DATA_PATH = Path(\"data\")\n",
        "PATH = DATA_PATH / \"mnist\"\n",
        "\n",
        "PATH.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "URL = \"http://deeplearning.net/data/mnist/\"\n",
        "FILENAME = \"mnist.pkl.gz\"\n",
        "\n",
        "if not (PATH / FILENAME).exists():\n",
        "  content = requests.get(URL + FILENAME).content\n",
        "  (PATH / FILENAME).open(\"wb\").write(content)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2FYIJgnKB5m",
        "colab_type": "text"
      },
      "source": [
        "This dataset is in numpy array format, and has been stored using pickle,\n",
        "a python-specific format for serializing data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUxx14xAKB5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import gzip\n",
        "\n",
        "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
        "  ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding = \"latin-1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1NQNcHXKB5v",
        "colab_type": "text"
      },
      "source": [
        "Each image is 28 x 28, and is being stored as a flattened row of length\n",
        "784 (=28x28). Let's take a look at one; we need to reshape it to 2d\n",
        "first.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC886xmkKB5w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "8fd42492-06f2-47fb-ffae-82bf431e9656"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "pyplot.imshow(x_train[0].reshape(28, 28), cmap = \"gray\")\n",
        "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784) (50000,) (10000, 784) (10000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSfr7EOOKB54",
        "colab_type": "text"
      },
      "source": [
        "PyTorch uses ``torch.tensor``, rather than numpy arrays, so we need to\n",
        "convert our data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo7w3xmdKB55",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "236e2383-0b0d-4ab0-c91b-9e025ae6367b"
      },
      "source": [
        "import torch\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = map(\n",
        "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
        ")\n",
        "\n",
        "n, c = x_train.shape\n",
        "x_train, x_train.shape, y_train.min(), y_train.max()\n",
        "print(x_train, y_train)\n",
        "print(x_train.shape)\n",
        "print(y_train.min(), y_train.max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
            "torch.Size([50000, 784])\n",
            "tensor(0) tensor(9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDvaR4kHKB6B",
        "colab_type": "text"
      },
      "source": [
        "Neural net from scratch (no torch.nn)\n",
        "---------------------------------------------\n",
        "\n",
        "Let's first create a model using nothing but PyTorch tensor operations. We're assuming\n",
        "you're already familiar with the basics of neural networks. (If you're not, you can\n",
        "learn them at `course.fast.ai <https://course.fast.ai>`_).\n",
        "\n",
        "PyTorch provides methods to create random or zero-filled tensors, which we will\n",
        "use to create our weights and bias for a simple linear model. These are just regular\n",
        "tensors, with one very special addition: we tell PyTorch that they require a\n",
        "gradient. This causes PyTorch to record all of the operations done on the tensor,\n",
        "so that it can calculate the gradient during back-propagation *automatically*!\n",
        "\n",
        "For the weights, we set ``requires_grad`` **after** the initialization, since we\n",
        "don't want that step included in the gradient. (Note that a trailling ``_`` in\n",
        "PyTorch signifies that the operation is performed in-place.)\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>We are initializing the weights here with\n",
        "   `Xavier initialisation <http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf>`_\n",
        "   (by multiplying with 1/sqrt(n)).</p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DR3JnzaKB6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "weights = torch.randn(784, 10) / math.sqrt(784)\n",
        "weights.requires_grad_()\n",
        "bias = torch.zeros(10, requires_grad = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPQY4hM_KB6K",
        "colab_type": "text"
      },
      "source": [
        "Thanks to PyTorch's ability to calculate gradients automatically, we can\n",
        "use any standard Python function (or callable object) as a model! So\n",
        "let's just write a plain matrix multiplication and broadcasted addition\n",
        "to create a simple linear model. We also need an activation function, so\n",
        "we'll write `log_softmax` and use it. Remember: although PyTorch\n",
        "provides lots of pre-written loss functions, activation functions, and\n",
        "so forth, you can easily write your own using plain python. PyTorch will\n",
        "even create fast GPU or vectorized CPU code for your function\n",
        "automatically.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-K_yXGBKB6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x):\n",
        "  return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
        "\n",
        "def model(xb):\n",
        "  return log_softmax(xb @ weights + bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6NaOIIlKB6R",
        "colab_type": "text"
      },
      "source": [
        "In the above, the ``@`` stands for the dot product operation. We will call\n",
        "our function on one batch of data (in this case, 64 images).  This is\n",
        "one *forward pass*.  Note that our predictions won't be any better than\n",
        "random at this stage, since we start with random weights.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1_-puugKB6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "381673f1-9411-4be6-daa6-e3cfbd0cfbe9"
      },
      "source": [
        "bs = 64 # batch size\n",
        "\n",
        "xb = x_train[0:bs] # a mini batch from x\n",
        "preds = model(xb)  # predictions\n",
        "preds[0], preds.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-1.9060, -2.4330, -2.5820, -2.8521, -2.4680, -2.9242, -1.8505, -2.7659,\n",
              "         -2.3038, -1.7614], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqLDUuFRKB6a",
        "colab_type": "text"
      },
      "source": [
        "As you see, the ``preds`` tensor contains not only the tensor values, but also a\n",
        "gradient function. We'll use this later to do backprop.\n",
        "\n",
        "Let's implement negative log-likelihood to use as the loss function\n",
        "(again, we can just use standard Python):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJUSvyCYKB6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input - predictions [bs, no_classes]\n",
        "# target - Actual values [bs]\n",
        "\n",
        "def nll(input, target):\n",
        "  '''\n",
        "  print(target)\n",
        "  print(target.shape)\n",
        "  print(input.shape)\n",
        "  print(target[0])\n",
        "  print(input[0])\n",
        "  print(target.shape[0])\n",
        "  print(input.shape[0])\n",
        "  print(range(target.shape[0]))\n",
        "  print(input[0, target])\n",
        "  print(input[range(target.shape[0]), target])\n",
        "  '''\n",
        "  return -input[range(target.shape[0]), target].mean()\n",
        "\n",
        "loss_func = nll"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7jFLan7KB6i",
        "colab_type": "text"
      },
      "source": [
        "Let's check our loss with our random model, so we can see if we improve\n",
        "after a backprop pass later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro63ZP_PKB6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "680c52e3-cde4-4a55-9a3a-a2c5615b3c88"
      },
      "source": [
        "yb = y_train[0:bs]\n",
        "\n",
        "print(loss_func(preds, yb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2392, grad_fn=<NegBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t-VNdVeKB6p",
        "colab_type": "text"
      },
      "source": [
        "Let's also implement a function to calculate the accuracy of our model.\n",
        "For each prediction, if the index with the largest value matches the\n",
        "target value, then the prediction was correct.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqLC5GKoKB6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, yb):\n",
        "  preds = torch.argmax(out, dim = 1)\n",
        "  return (preds == yb).float().mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPkzdYmJKB6x",
        "colab_type": "text"
      },
      "source": [
        "Let's check the accuracy of our random model, so we can see if our\n",
        "accuracy improves as our loss improves.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb_paNTIKB6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "eecd998c-0848-4394-8385-e402098b3a69"
      },
      "source": [
        "print(accuracy(preds, yb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1875)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK6J0aRqKB66",
        "colab_type": "text"
      },
      "source": [
        "We can now run a training loop.  For each iteration, we will:\n",
        "\n",
        "- select a mini-batch of data (of size ``bs``)\n",
        "- use the model to make predictions\n",
        "- calculate the loss\n",
        "- ``loss.backward()`` updates the gradients of the model, in this case, ``weights``\n",
        "  and ``bias``.\n",
        "\n",
        "We now use these gradients to update the weights and bias.  We do this\n",
        "within the ``torch.no_grad()`` context manager, because we do not want these\n",
        "actions to be recorded for our next calculation of the gradient.  You can read\n",
        "more about how PyTorch's Autograd records operations\n",
        "`here <https://pytorch.org/docs/stable/notes/autograd.html>`_.\n",
        "\n",
        "We then set the\n",
        "gradients to zero, so that we are ready for the next loop.\n",
        "Otherwise, our gradients would record a running tally of all the operations\n",
        "that had happened (i.e. ``loss.backward()`` *adds* the gradients to whatever is\n",
        "already stored, rather than replacing them).\n",
        "\n",
        ".. tip:: You can use the standard python debugger to step through PyTorch\n",
        "   code, allowing you to check the various variable values at each step.\n",
        "   Uncomment ``set_trace()`` below to try it out.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgyrQHOVFORV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9fde3e20-f073-46ae-cad3-c736785760ad"
      },
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "lr = 0.5\n",
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i in range((n - 1) // bs + 1):\n",
        "    # set_trace()\n",
        "\n",
        "    start_i = i * bs \n",
        "    end_i = start_i + bs\n",
        "    xb = x_train[start_i : end_i]\n",
        "    yb = y_train[start_i : end_i]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "    print(loss)\n",
        "    with torch.no_grad():\n",
        "      weights -= weights.grad * lr\n",
        "      bias -= bias.grad * lr\n",
        "      weights.grad.zero_()\n",
        "      bias.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2392, grad_fn=<NegBackward>)\n",
            "tensor(1.7570, grad_fn=<NegBackward>)\n",
            "tensor(1.8898, grad_fn=<NegBackward>)\n",
            "tensor(1.5268, grad_fn=<NegBackward>)\n",
            "tensor(1.3059, grad_fn=<NegBackward>)\n",
            "tensor(0.9805, grad_fn=<NegBackward>)\n",
            "tensor(0.8871, grad_fn=<NegBackward>)\n",
            "tensor(1.0751, grad_fn=<NegBackward>)\n",
            "tensor(0.9403, grad_fn=<NegBackward>)\n",
            "tensor(1.1281, grad_fn=<NegBackward>)\n",
            "tensor(0.8941, grad_fn=<NegBackward>)\n",
            "tensor(0.9310, grad_fn=<NegBackward>)\n",
            "tensor(0.8454, grad_fn=<NegBackward>)\n",
            "tensor(0.9364, grad_fn=<NegBackward>)\n",
            "tensor(1.0381, grad_fn=<NegBackward>)\n",
            "tensor(0.7436, grad_fn=<NegBackward>)\n",
            "tensor(1.0182, grad_fn=<NegBackward>)\n",
            "tensor(0.9657, grad_fn=<NegBackward>)\n",
            "tensor(0.5401, grad_fn=<NegBackward>)\n",
            "tensor(0.6512, grad_fn=<NegBackward>)\n",
            "tensor(0.6719, grad_fn=<NegBackward>)\n",
            "tensor(1.0562, grad_fn=<NegBackward>)\n",
            "tensor(1.1042, grad_fn=<NegBackward>)\n",
            "tensor(0.9602, grad_fn=<NegBackward>)\n",
            "tensor(0.5132, grad_fn=<NegBackward>)\n",
            "tensor(0.5322, grad_fn=<NegBackward>)\n",
            "tensor(0.4241, grad_fn=<NegBackward>)\n",
            "tensor(0.5378, grad_fn=<NegBackward>)\n",
            "tensor(0.5893, grad_fn=<NegBackward>)\n",
            "tensor(0.4897, grad_fn=<NegBackward>)\n",
            "tensor(0.4817, grad_fn=<NegBackward>)\n",
            "tensor(0.5297, grad_fn=<NegBackward>)\n",
            "tensor(0.4594, grad_fn=<NegBackward>)\n",
            "tensor(0.3271, grad_fn=<NegBackward>)\n",
            "tensor(0.5046, grad_fn=<NegBackward>)\n",
            "tensor(0.4335, grad_fn=<NegBackward>)\n",
            "tensor(0.4032, grad_fn=<NegBackward>)\n",
            "tensor(0.6099, grad_fn=<NegBackward>)\n",
            "tensor(0.4676, grad_fn=<NegBackward>)\n",
            "tensor(0.3316, grad_fn=<NegBackward>)\n",
            "tensor(0.4318, grad_fn=<NegBackward>)\n",
            "tensor(0.5865, grad_fn=<NegBackward>)\n",
            "tensor(0.6026, grad_fn=<NegBackward>)\n",
            "tensor(0.5288, grad_fn=<NegBackward>)\n",
            "tensor(0.3545, grad_fn=<NegBackward>)\n",
            "tensor(0.4688, grad_fn=<NegBackward>)\n",
            "tensor(0.4061, grad_fn=<NegBackward>)\n",
            "tensor(0.6052, grad_fn=<NegBackward>)\n",
            "tensor(0.3915, grad_fn=<NegBackward>)\n",
            "tensor(0.3628, grad_fn=<NegBackward>)\n",
            "tensor(0.4082, grad_fn=<NegBackward>)\n",
            "tensor(0.4550, grad_fn=<NegBackward>)\n",
            "tensor(0.3962, grad_fn=<NegBackward>)\n",
            "tensor(0.4540, grad_fn=<NegBackward>)\n",
            "tensor(0.4217, grad_fn=<NegBackward>)\n",
            "tensor(0.4649, grad_fn=<NegBackward>)\n",
            "tensor(0.2862, grad_fn=<NegBackward>)\n",
            "tensor(0.5192, grad_fn=<NegBackward>)\n",
            "tensor(0.5511, grad_fn=<NegBackward>)\n",
            "tensor(0.4748, grad_fn=<NegBackward>)\n",
            "tensor(0.3181, grad_fn=<NegBackward>)\n",
            "tensor(0.3613, grad_fn=<NegBackward>)\n",
            "tensor(0.4635, grad_fn=<NegBackward>)\n",
            "tensor(0.5510, grad_fn=<NegBackward>)\n",
            "tensor(0.5011, grad_fn=<NegBackward>)\n",
            "tensor(0.4386, grad_fn=<NegBackward>)\n",
            "tensor(0.4467, grad_fn=<NegBackward>)\n",
            "tensor(0.4375, grad_fn=<NegBackward>)\n",
            "tensor(0.3967, grad_fn=<NegBackward>)\n",
            "tensor(0.3754, grad_fn=<NegBackward>)\n",
            "tensor(0.3725, grad_fn=<NegBackward>)\n",
            "tensor(0.2201, grad_fn=<NegBackward>)\n",
            "tensor(0.4576, grad_fn=<NegBackward>)\n",
            "tensor(0.4399, grad_fn=<NegBackward>)\n",
            "tensor(0.4954, grad_fn=<NegBackward>)\n",
            "tensor(0.4947, grad_fn=<NegBackward>)\n",
            "tensor(0.3006, grad_fn=<NegBackward>)\n",
            "tensor(0.5633, grad_fn=<NegBackward>)\n",
            "tensor(0.3868, grad_fn=<NegBackward>)\n",
            "tensor(0.4308, grad_fn=<NegBackward>)\n",
            "tensor(0.7692, grad_fn=<NegBackward>)\n",
            "tensor(0.2900, grad_fn=<NegBackward>)\n",
            "tensor(0.4961, grad_fn=<NegBackward>)\n",
            "tensor(0.3957, grad_fn=<NegBackward>)\n",
            "tensor(0.3111, grad_fn=<NegBackward>)\n",
            "tensor(0.2502, grad_fn=<NegBackward>)\n",
            "tensor(0.4880, grad_fn=<NegBackward>)\n",
            "tensor(0.3772, grad_fn=<NegBackward>)\n",
            "tensor(0.3560, grad_fn=<NegBackward>)\n",
            "tensor(0.4089, grad_fn=<NegBackward>)\n",
            "tensor(0.2990, grad_fn=<NegBackward>)\n",
            "tensor(0.4786, grad_fn=<NegBackward>)\n",
            "tensor(0.3708, grad_fn=<NegBackward>)\n",
            "tensor(0.3445, grad_fn=<NegBackward>)\n",
            "tensor(0.2423, grad_fn=<NegBackward>)\n",
            "tensor(0.3909, grad_fn=<NegBackward>)\n",
            "tensor(0.3299, grad_fn=<NegBackward>)\n",
            "tensor(0.3427, grad_fn=<NegBackward>)\n",
            "tensor(0.2905, grad_fn=<NegBackward>)\n",
            "tensor(0.2635, grad_fn=<NegBackward>)\n",
            "tensor(0.3107, grad_fn=<NegBackward>)\n",
            "tensor(0.5040, grad_fn=<NegBackward>)\n",
            "tensor(0.2584, grad_fn=<NegBackward>)\n",
            "tensor(0.3189, grad_fn=<NegBackward>)\n",
            "tensor(0.3221, grad_fn=<NegBackward>)\n",
            "tensor(0.2752, grad_fn=<NegBackward>)\n",
            "tensor(0.5112, grad_fn=<NegBackward>)\n",
            "tensor(0.4523, grad_fn=<NegBackward>)\n",
            "tensor(0.5960, grad_fn=<NegBackward>)\n",
            "tensor(0.6802, grad_fn=<NegBackward>)\n",
            "tensor(0.3113, grad_fn=<NegBackward>)\n",
            "tensor(0.4554, grad_fn=<NegBackward>)\n",
            "tensor(0.4950, grad_fn=<NegBackward>)\n",
            "tensor(0.6428, grad_fn=<NegBackward>)\n",
            "tensor(0.5572, grad_fn=<NegBackward>)\n",
            "tensor(0.3005, grad_fn=<NegBackward>)\n",
            "tensor(0.3371, grad_fn=<NegBackward>)\n",
            "tensor(0.4305, grad_fn=<NegBackward>)\n",
            "tensor(0.2437, grad_fn=<NegBackward>)\n",
            "tensor(0.4927, grad_fn=<NegBackward>)\n",
            "tensor(0.3629, grad_fn=<NegBackward>)\n",
            "tensor(0.4050, grad_fn=<NegBackward>)\n",
            "tensor(0.5453, grad_fn=<NegBackward>)\n",
            "tensor(0.5171, grad_fn=<NegBackward>)\n",
            "tensor(0.3934, grad_fn=<NegBackward>)\n",
            "tensor(0.3314, grad_fn=<NegBackward>)\n",
            "tensor(0.5248, grad_fn=<NegBackward>)\n",
            "tensor(0.2416, grad_fn=<NegBackward>)\n",
            "tensor(0.6713, grad_fn=<NegBackward>)\n",
            "tensor(0.4641, grad_fn=<NegBackward>)\n",
            "tensor(0.2605, grad_fn=<NegBackward>)\n",
            "tensor(0.4467, grad_fn=<NegBackward>)\n",
            "tensor(0.5061, grad_fn=<NegBackward>)\n",
            "tensor(0.2932, grad_fn=<NegBackward>)\n",
            "tensor(0.3232, grad_fn=<NegBackward>)\n",
            "tensor(0.6952, grad_fn=<NegBackward>)\n",
            "tensor(0.8149, grad_fn=<NegBackward>)\n",
            "tensor(0.5717, grad_fn=<NegBackward>)\n",
            "tensor(0.7199, grad_fn=<NegBackward>)\n",
            "tensor(0.5331, grad_fn=<NegBackward>)\n",
            "tensor(0.3173, grad_fn=<NegBackward>)\n",
            "tensor(0.1907, grad_fn=<NegBackward>)\n",
            "tensor(0.4853, grad_fn=<NegBackward>)\n",
            "tensor(0.2395, grad_fn=<NegBackward>)\n",
            "tensor(0.5070, grad_fn=<NegBackward>)\n",
            "tensor(0.4149, grad_fn=<NegBackward>)\n",
            "tensor(0.4836, grad_fn=<NegBackward>)\n",
            "tensor(0.6065, grad_fn=<NegBackward>)\n",
            "tensor(0.3049, grad_fn=<NegBackward>)\n",
            "tensor(0.3825, grad_fn=<NegBackward>)\n",
            "tensor(0.2792, grad_fn=<NegBackward>)\n",
            "tensor(0.1959, grad_fn=<NegBackward>)\n",
            "tensor(0.5843, grad_fn=<NegBackward>)\n",
            "tensor(0.2147, grad_fn=<NegBackward>)\n",
            "tensor(0.2558, grad_fn=<NegBackward>)\n",
            "tensor(0.3407, grad_fn=<NegBackward>)\n",
            "tensor(0.4140, grad_fn=<NegBackward>)\n",
            "tensor(0.2557, grad_fn=<NegBackward>)\n",
            "tensor(0.2635, grad_fn=<NegBackward>)\n",
            "tensor(0.4401, grad_fn=<NegBackward>)\n",
            "tensor(0.3754, grad_fn=<NegBackward>)\n",
            "tensor(0.2279, grad_fn=<NegBackward>)\n",
            "tensor(0.2378, grad_fn=<NegBackward>)\n",
            "tensor(0.3159, grad_fn=<NegBackward>)\n",
            "tensor(0.1499, grad_fn=<NegBackward>)\n",
            "tensor(0.1825, grad_fn=<NegBackward>)\n",
            "tensor(0.3141, grad_fn=<NegBackward>)\n",
            "tensor(0.4343, grad_fn=<NegBackward>)\n",
            "tensor(0.3713, grad_fn=<NegBackward>)\n",
            "tensor(0.2793, grad_fn=<NegBackward>)\n",
            "tensor(0.2810, grad_fn=<NegBackward>)\n",
            "tensor(0.3132, grad_fn=<NegBackward>)\n",
            "tensor(0.2587, grad_fn=<NegBackward>)\n",
            "tensor(0.2989, grad_fn=<NegBackward>)\n",
            "tensor(0.2008, grad_fn=<NegBackward>)\n",
            "tensor(0.4577, grad_fn=<NegBackward>)\n",
            "tensor(0.1942, grad_fn=<NegBackward>)\n",
            "tensor(0.2931, grad_fn=<NegBackward>)\n",
            "tensor(0.2533, grad_fn=<NegBackward>)\n",
            "tensor(0.3204, grad_fn=<NegBackward>)\n",
            "tensor(0.6332, grad_fn=<NegBackward>)\n",
            "tensor(0.4972, grad_fn=<NegBackward>)\n",
            "tensor(0.5703, grad_fn=<NegBackward>)\n",
            "tensor(0.4533, grad_fn=<NegBackward>)\n",
            "tensor(0.2736, grad_fn=<NegBackward>)\n",
            "tensor(0.4006, grad_fn=<NegBackward>)\n",
            "tensor(0.2777, grad_fn=<NegBackward>)\n",
            "tensor(0.2753, grad_fn=<NegBackward>)\n",
            "tensor(0.3820, grad_fn=<NegBackward>)\n",
            "tensor(0.2720, grad_fn=<NegBackward>)\n",
            "tensor(0.4657, grad_fn=<NegBackward>)\n",
            "tensor(0.3992, grad_fn=<NegBackward>)\n",
            "tensor(0.3856, grad_fn=<NegBackward>)\n",
            "tensor(0.4426, grad_fn=<NegBackward>)\n",
            "tensor(0.4066, grad_fn=<NegBackward>)\n",
            "tensor(0.4584, grad_fn=<NegBackward>)\n",
            "tensor(0.6646, grad_fn=<NegBackward>)\n",
            "tensor(0.7484, grad_fn=<NegBackward>)\n",
            "tensor(0.5811, grad_fn=<NegBackward>)\n",
            "tensor(0.4465, grad_fn=<NegBackward>)\n",
            "tensor(0.2973, grad_fn=<NegBackward>)\n",
            "tensor(0.3001, grad_fn=<NegBackward>)\n",
            "tensor(0.5747, grad_fn=<NegBackward>)\n",
            "tensor(0.6509, grad_fn=<NegBackward>)\n",
            "tensor(0.5744, grad_fn=<NegBackward>)\n",
            "tensor(0.5064, grad_fn=<NegBackward>)\n",
            "tensor(0.3285, grad_fn=<NegBackward>)\n",
            "tensor(0.3466, grad_fn=<NegBackward>)\n",
            "tensor(0.3825, grad_fn=<NegBackward>)\n",
            "tensor(0.3252, grad_fn=<NegBackward>)\n",
            "tensor(0.2392, grad_fn=<NegBackward>)\n",
            "tensor(0.4542, grad_fn=<NegBackward>)\n",
            "tensor(0.1701, grad_fn=<NegBackward>)\n",
            "tensor(0.5337, grad_fn=<NegBackward>)\n",
            "tensor(0.5311, grad_fn=<NegBackward>)\n",
            "tensor(0.2777, grad_fn=<NegBackward>)\n",
            "tensor(0.4163, grad_fn=<NegBackward>)\n",
            "tensor(0.4491, grad_fn=<NegBackward>)\n",
            "tensor(0.6597, grad_fn=<NegBackward>)\n",
            "tensor(0.5218, grad_fn=<NegBackward>)\n",
            "tensor(0.4603, grad_fn=<NegBackward>)\n",
            "tensor(0.4394, grad_fn=<NegBackward>)\n",
            "tensor(0.4207, grad_fn=<NegBackward>)\n",
            "tensor(0.5417, grad_fn=<NegBackward>)\n",
            "tensor(0.7289, grad_fn=<NegBackward>)\n",
            "tensor(0.3821, grad_fn=<NegBackward>)\n",
            "tensor(0.3582, grad_fn=<NegBackward>)\n",
            "tensor(0.4899, grad_fn=<NegBackward>)\n",
            "tensor(0.5183, grad_fn=<NegBackward>)\n",
            "tensor(0.5211, grad_fn=<NegBackward>)\n",
            "tensor(0.6031, grad_fn=<NegBackward>)\n",
            "tensor(0.6868, grad_fn=<NegBackward>)\n",
            "tensor(0.3312, grad_fn=<NegBackward>)\n",
            "tensor(0.2540, grad_fn=<NegBackward>)\n",
            "tensor(0.2456, grad_fn=<NegBackward>)\n",
            "tensor(0.2523, grad_fn=<NegBackward>)\n",
            "tensor(0.5907, grad_fn=<NegBackward>)\n",
            "tensor(0.3808, grad_fn=<NegBackward>)\n",
            "tensor(0.3578, grad_fn=<NegBackward>)\n",
            "tensor(0.2716, grad_fn=<NegBackward>)\n",
            "tensor(0.2613, grad_fn=<NegBackward>)\n",
            "tensor(0.2972, grad_fn=<NegBackward>)\n",
            "tensor(0.4005, grad_fn=<NegBackward>)\n",
            "tensor(0.3191, grad_fn=<NegBackward>)\n",
            "tensor(0.2610, grad_fn=<NegBackward>)\n",
            "tensor(0.4436, grad_fn=<NegBackward>)\n",
            "tensor(0.4443, grad_fn=<NegBackward>)\n",
            "tensor(0.3754, grad_fn=<NegBackward>)\n",
            "tensor(0.3751, grad_fn=<NegBackward>)\n",
            "tensor(0.6656, grad_fn=<NegBackward>)\n",
            "tensor(0.5552, grad_fn=<NegBackward>)\n",
            "tensor(0.3189, grad_fn=<NegBackward>)\n",
            "tensor(0.2088, grad_fn=<NegBackward>)\n",
            "tensor(0.3343, grad_fn=<NegBackward>)\n",
            "tensor(0.3340, grad_fn=<NegBackward>)\n",
            "tensor(0.3161, grad_fn=<NegBackward>)\n",
            "tensor(0.2510, grad_fn=<NegBackward>)\n",
            "tensor(0.3513, grad_fn=<NegBackward>)\n",
            "tensor(0.4567, grad_fn=<NegBackward>)\n",
            "tensor(0.3465, grad_fn=<NegBackward>)\n",
            "tensor(0.4339, grad_fn=<NegBackward>)\n",
            "tensor(0.3500, grad_fn=<NegBackward>)\n",
            "tensor(0.4487, grad_fn=<NegBackward>)\n",
            "tensor(0.3248, grad_fn=<NegBackward>)\n",
            "tensor(0.3437, grad_fn=<NegBackward>)\n",
            "tensor(0.4396, grad_fn=<NegBackward>)\n",
            "tensor(0.3814, grad_fn=<NegBackward>)\n",
            "tensor(0.3725, grad_fn=<NegBackward>)\n",
            "tensor(0.4432, grad_fn=<NegBackward>)\n",
            "tensor(0.4332, grad_fn=<NegBackward>)\n",
            "tensor(0.2207, grad_fn=<NegBackward>)\n",
            "tensor(0.3713, grad_fn=<NegBackward>)\n",
            "tensor(0.2817, grad_fn=<NegBackward>)\n",
            "tensor(0.4839, grad_fn=<NegBackward>)\n",
            "tensor(0.6551, grad_fn=<NegBackward>)\n",
            "tensor(0.3075, grad_fn=<NegBackward>)\n",
            "tensor(0.4803, grad_fn=<NegBackward>)\n",
            "tensor(0.3575, grad_fn=<NegBackward>)\n",
            "tensor(0.5780, grad_fn=<NegBackward>)\n",
            "tensor(0.3436, grad_fn=<NegBackward>)\n",
            "tensor(0.2682, grad_fn=<NegBackward>)\n",
            "tensor(0.3005, grad_fn=<NegBackward>)\n",
            "tensor(0.3011, grad_fn=<NegBackward>)\n",
            "tensor(0.2076, grad_fn=<NegBackward>)\n",
            "tensor(0.2076, grad_fn=<NegBackward>)\n",
            "tensor(0.2481, grad_fn=<NegBackward>)\n",
            "tensor(0.2799, grad_fn=<NegBackward>)\n",
            "tensor(0.3248, grad_fn=<NegBackward>)\n",
            "tensor(0.3426, grad_fn=<NegBackward>)\n",
            "tensor(0.2411, grad_fn=<NegBackward>)\n",
            "tensor(0.4501, grad_fn=<NegBackward>)\n",
            "tensor(0.2680, grad_fn=<NegBackward>)\n",
            "tensor(0.3888, grad_fn=<NegBackward>)\n",
            "tensor(0.1836, grad_fn=<NegBackward>)\n",
            "tensor(0.3554, grad_fn=<NegBackward>)\n",
            "tensor(0.2075, grad_fn=<NegBackward>)\n",
            "tensor(0.2310, grad_fn=<NegBackward>)\n",
            "tensor(0.3756, grad_fn=<NegBackward>)\n",
            "tensor(0.3725, grad_fn=<NegBackward>)\n",
            "tensor(0.2894, grad_fn=<NegBackward>)\n",
            "tensor(0.3854, grad_fn=<NegBackward>)\n",
            "tensor(0.3450, grad_fn=<NegBackward>)\n",
            "tensor(0.3598, grad_fn=<NegBackward>)\n",
            "tensor(0.3580, grad_fn=<NegBackward>)\n",
            "tensor(0.3530, grad_fn=<NegBackward>)\n",
            "tensor(0.3923, grad_fn=<NegBackward>)\n",
            "tensor(0.2688, grad_fn=<NegBackward>)\n",
            "tensor(0.1615, grad_fn=<NegBackward>)\n",
            "tensor(0.1043, grad_fn=<NegBackward>)\n",
            "tensor(0.4480, grad_fn=<NegBackward>)\n",
            "tensor(0.2307, grad_fn=<NegBackward>)\n",
            "tensor(0.4063, grad_fn=<NegBackward>)\n",
            "tensor(0.4541, grad_fn=<NegBackward>)\n",
            "tensor(0.4087, grad_fn=<NegBackward>)\n",
            "tensor(0.2652, grad_fn=<NegBackward>)\n",
            "tensor(0.6001, grad_fn=<NegBackward>)\n",
            "tensor(0.2634, grad_fn=<NegBackward>)\n",
            "tensor(0.3072, grad_fn=<NegBackward>)\n",
            "tensor(0.1908, grad_fn=<NegBackward>)\n",
            "tensor(0.2319, grad_fn=<NegBackward>)\n",
            "tensor(0.2206, grad_fn=<NegBackward>)\n",
            "tensor(0.4818, grad_fn=<NegBackward>)\n",
            "tensor(0.2890, grad_fn=<NegBackward>)\n",
            "tensor(0.4922, grad_fn=<NegBackward>)\n",
            "tensor(0.3734, grad_fn=<NegBackward>)\n",
            "tensor(0.4566, grad_fn=<NegBackward>)\n",
            "tensor(0.5813, grad_fn=<NegBackward>)\n",
            "tensor(0.7078, grad_fn=<NegBackward>)\n",
            "tensor(0.4437, grad_fn=<NegBackward>)\n",
            "tensor(0.3779, grad_fn=<NegBackward>)\n",
            "tensor(0.3171, grad_fn=<NegBackward>)\n",
            "tensor(0.3077, grad_fn=<NegBackward>)\n",
            "tensor(0.2110, grad_fn=<NegBackward>)\n",
            "tensor(0.3031, grad_fn=<NegBackward>)\n",
            "tensor(0.3839, grad_fn=<NegBackward>)\n",
            "tensor(0.1348, grad_fn=<NegBackward>)\n",
            "tensor(0.2505, grad_fn=<NegBackward>)\n",
            "tensor(0.5536, grad_fn=<NegBackward>)\n",
            "tensor(0.2704, grad_fn=<NegBackward>)\n",
            "tensor(0.2835, grad_fn=<NegBackward>)\n",
            "tensor(0.0987, grad_fn=<NegBackward>)\n",
            "tensor(0.1467, grad_fn=<NegBackward>)\n",
            "tensor(0.3079, grad_fn=<NegBackward>)\n",
            "tensor(0.3501, grad_fn=<NegBackward>)\n",
            "tensor(0.1680, grad_fn=<NegBackward>)\n",
            "tensor(0.4631, grad_fn=<NegBackward>)\n",
            "tensor(0.4471, grad_fn=<NegBackward>)\n",
            "tensor(0.4735, grad_fn=<NegBackward>)\n",
            "tensor(0.3311, grad_fn=<NegBackward>)\n",
            "tensor(0.1108, grad_fn=<NegBackward>)\n",
            "tensor(0.2989, grad_fn=<NegBackward>)\n",
            "tensor(0.6640, grad_fn=<NegBackward>)\n",
            "tensor(0.7960, grad_fn=<NegBackward>)\n",
            "tensor(0.5215, grad_fn=<NegBackward>)\n",
            "tensor(0.3266, grad_fn=<NegBackward>)\n",
            "tensor(0.3435, grad_fn=<NegBackward>)\n",
            "tensor(0.3162, grad_fn=<NegBackward>)\n",
            "tensor(0.2335, grad_fn=<NegBackward>)\n",
            "tensor(0.1318, grad_fn=<NegBackward>)\n",
            "tensor(0.2703, grad_fn=<NegBackward>)\n",
            "tensor(0.4500, grad_fn=<NegBackward>)\n",
            "tensor(0.3595, grad_fn=<NegBackward>)\n",
            "tensor(0.3519, grad_fn=<NegBackward>)\n",
            "tensor(0.1801, grad_fn=<NegBackward>)\n",
            "tensor(0.2638, grad_fn=<NegBackward>)\n",
            "tensor(0.2730, grad_fn=<NegBackward>)\n",
            "tensor(0.3372, grad_fn=<NegBackward>)\n",
            "tensor(0.2994, grad_fn=<NegBackward>)\n",
            "tensor(0.2612, grad_fn=<NegBackward>)\n",
            "tensor(0.2973, grad_fn=<NegBackward>)\n",
            "tensor(0.5857, grad_fn=<NegBackward>)\n",
            "tensor(0.2319, grad_fn=<NegBackward>)\n",
            "tensor(0.4203, grad_fn=<NegBackward>)\n",
            "tensor(0.3360, grad_fn=<NegBackward>)\n",
            "tensor(0.4680, grad_fn=<NegBackward>)\n",
            "tensor(0.3980, grad_fn=<NegBackward>)\n",
            "tensor(0.2473, grad_fn=<NegBackward>)\n",
            "tensor(0.2292, grad_fn=<NegBackward>)\n",
            "tensor(0.4036, grad_fn=<NegBackward>)\n",
            "tensor(0.4760, grad_fn=<NegBackward>)\n",
            "tensor(0.2355, grad_fn=<NegBackward>)\n",
            "tensor(0.2864, grad_fn=<NegBackward>)\n",
            "tensor(0.3774, grad_fn=<NegBackward>)\n",
            "tensor(0.4519, grad_fn=<NegBackward>)\n",
            "tensor(0.3767, grad_fn=<NegBackward>)\n",
            "tensor(0.4140, grad_fn=<NegBackward>)\n",
            "tensor(0.3714, grad_fn=<NegBackward>)\n",
            "tensor(0.5161, grad_fn=<NegBackward>)\n",
            "tensor(0.3022, grad_fn=<NegBackward>)\n",
            "tensor(0.4062, grad_fn=<NegBackward>)\n",
            "tensor(0.3522, grad_fn=<NegBackward>)\n",
            "tensor(0.1469, grad_fn=<NegBackward>)\n",
            "tensor(0.3503, grad_fn=<NegBackward>)\n",
            "tensor(0.3196, grad_fn=<NegBackward>)\n",
            "tensor(0.2905, grad_fn=<NegBackward>)\n",
            "tensor(0.5036, grad_fn=<NegBackward>)\n",
            "tensor(0.1295, grad_fn=<NegBackward>)\n",
            "tensor(0.1222, grad_fn=<NegBackward>)\n",
            "tensor(0.2370, grad_fn=<NegBackward>)\n",
            "tensor(0.3508, grad_fn=<NegBackward>)\n",
            "tensor(0.2324, grad_fn=<NegBackward>)\n",
            "tensor(0.2389, grad_fn=<NegBackward>)\n",
            "tensor(0.2689, grad_fn=<NegBackward>)\n",
            "tensor(0.4318, grad_fn=<NegBackward>)\n",
            "tensor(0.1997, grad_fn=<NegBackward>)\n",
            "tensor(0.2805, grad_fn=<NegBackward>)\n",
            "tensor(0.2313, grad_fn=<NegBackward>)\n",
            "tensor(0.2509, grad_fn=<NegBackward>)\n",
            "tensor(0.2173, grad_fn=<NegBackward>)\n",
            "tensor(0.2194, grad_fn=<NegBackward>)\n",
            "tensor(0.3523, grad_fn=<NegBackward>)\n",
            "tensor(0.3082, grad_fn=<NegBackward>)\n",
            "tensor(0.6025, grad_fn=<NegBackward>)\n",
            "tensor(0.4381, grad_fn=<NegBackward>)\n",
            "tensor(0.3569, grad_fn=<NegBackward>)\n",
            "tensor(0.3939, grad_fn=<NegBackward>)\n",
            "tensor(0.6268, grad_fn=<NegBackward>)\n",
            "tensor(0.6327, grad_fn=<NegBackward>)\n",
            "tensor(0.3797, grad_fn=<NegBackward>)\n",
            "tensor(0.4121, grad_fn=<NegBackward>)\n",
            "tensor(0.5083, grad_fn=<NegBackward>)\n",
            "tensor(0.1433, grad_fn=<NegBackward>)\n",
            "tensor(0.1934, grad_fn=<NegBackward>)\n",
            "tensor(0.2627, grad_fn=<NegBackward>)\n",
            "tensor(0.6957, grad_fn=<NegBackward>)\n",
            "tensor(0.3683, grad_fn=<NegBackward>)\n",
            "tensor(0.1940, grad_fn=<NegBackward>)\n",
            "tensor(0.3227, grad_fn=<NegBackward>)\n",
            "tensor(0.3379, grad_fn=<NegBackward>)\n",
            "tensor(0.4386, grad_fn=<NegBackward>)\n",
            "tensor(0.2228, grad_fn=<NegBackward>)\n",
            "tensor(0.3854, grad_fn=<NegBackward>)\n",
            "tensor(0.3142, grad_fn=<NegBackward>)\n",
            "tensor(0.2493, grad_fn=<NegBackward>)\n",
            "tensor(0.3822, grad_fn=<NegBackward>)\n",
            "tensor(0.2487, grad_fn=<NegBackward>)\n",
            "tensor(0.2004, grad_fn=<NegBackward>)\n",
            "tensor(0.2259, grad_fn=<NegBackward>)\n",
            "tensor(0.1896, grad_fn=<NegBackward>)\n",
            "tensor(0.3309, grad_fn=<NegBackward>)\n",
            "tensor(0.3147, grad_fn=<NegBackward>)\n",
            "tensor(0.2465, grad_fn=<NegBackward>)\n",
            "tensor(0.1550, grad_fn=<NegBackward>)\n",
            "tensor(0.7211, grad_fn=<NegBackward>)\n",
            "tensor(0.2442, grad_fn=<NegBackward>)\n",
            "tensor(0.3531, grad_fn=<NegBackward>)\n",
            "tensor(0.3189, grad_fn=<NegBackward>)\n",
            "tensor(0.9132, grad_fn=<NegBackward>)\n",
            "tensor(0.3155, grad_fn=<NegBackward>)\n",
            "tensor(0.2630, grad_fn=<NegBackward>)\n",
            "tensor(0.2168, grad_fn=<NegBackward>)\n",
            "tensor(0.1514, grad_fn=<NegBackward>)\n",
            "tensor(0.3247, grad_fn=<NegBackward>)\n",
            "tensor(0.1594, grad_fn=<NegBackward>)\n",
            "tensor(0.4445, grad_fn=<NegBackward>)\n",
            "tensor(0.5080, grad_fn=<NegBackward>)\n",
            "tensor(0.4284, grad_fn=<NegBackward>)\n",
            "tensor(0.3473, grad_fn=<NegBackward>)\n",
            "tensor(0.3188, grad_fn=<NegBackward>)\n",
            "tensor(0.3388, grad_fn=<NegBackward>)\n",
            "tensor(0.2355, grad_fn=<NegBackward>)\n",
            "tensor(0.2704, grad_fn=<NegBackward>)\n",
            "tensor(0.2830, grad_fn=<NegBackward>)\n",
            "tensor(0.3413, grad_fn=<NegBackward>)\n",
            "tensor(0.4943, grad_fn=<NegBackward>)\n",
            "tensor(0.2428, grad_fn=<NegBackward>)\n",
            "tensor(0.5811, grad_fn=<NegBackward>)\n",
            "tensor(0.5096, grad_fn=<NegBackward>)\n",
            "tensor(0.4832, grad_fn=<NegBackward>)\n",
            "tensor(0.3684, grad_fn=<NegBackward>)\n",
            "tensor(0.4261, grad_fn=<NegBackward>)\n",
            "tensor(0.4940, grad_fn=<NegBackward>)\n",
            "tensor(0.4118, grad_fn=<NegBackward>)\n",
            "tensor(0.2431, grad_fn=<NegBackward>)\n",
            "tensor(0.1831, grad_fn=<NegBackward>)\n",
            "tensor(0.3117, grad_fn=<NegBackward>)\n",
            "tensor(0.3991, grad_fn=<NegBackward>)\n",
            "tensor(0.3072, grad_fn=<NegBackward>)\n",
            "tensor(0.4834, grad_fn=<NegBackward>)\n",
            "tensor(0.3921, grad_fn=<NegBackward>)\n",
            "tensor(0.3809, grad_fn=<NegBackward>)\n",
            "tensor(0.3394, grad_fn=<NegBackward>)\n",
            "tensor(0.4797, grad_fn=<NegBackward>)\n",
            "tensor(0.2753, grad_fn=<NegBackward>)\n",
            "tensor(0.4376, grad_fn=<NegBackward>)\n",
            "tensor(0.3330, grad_fn=<NegBackward>)\n",
            "tensor(0.5147, grad_fn=<NegBackward>)\n",
            "tensor(0.5704, grad_fn=<NegBackward>)\n",
            "tensor(0.4121, grad_fn=<NegBackward>)\n",
            "tensor(0.7713, grad_fn=<NegBackward>)\n",
            "tensor(0.5926, grad_fn=<NegBackward>)\n",
            "tensor(0.3903, grad_fn=<NegBackward>)\n",
            "tensor(0.1720, grad_fn=<NegBackward>)\n",
            "tensor(0.3096, grad_fn=<NegBackward>)\n",
            "tensor(0.4924, grad_fn=<NegBackward>)\n",
            "tensor(0.6270, grad_fn=<NegBackward>)\n",
            "tensor(0.4179, grad_fn=<NegBackward>)\n",
            "tensor(0.2900, grad_fn=<NegBackward>)\n",
            "tensor(0.3030, grad_fn=<NegBackward>)\n",
            "tensor(0.3623, grad_fn=<NegBackward>)\n",
            "tensor(0.3841, grad_fn=<NegBackward>)\n",
            "tensor(0.3779, grad_fn=<NegBackward>)\n",
            "tensor(0.4698, grad_fn=<NegBackward>)\n",
            "tensor(0.3713, grad_fn=<NegBackward>)\n",
            "tensor(0.4976, grad_fn=<NegBackward>)\n",
            "tensor(0.5029, grad_fn=<NegBackward>)\n",
            "tensor(0.4816, grad_fn=<NegBackward>)\n",
            "tensor(0.4808, grad_fn=<NegBackward>)\n",
            "tensor(0.2610, grad_fn=<NegBackward>)\n",
            "tensor(0.1257, grad_fn=<NegBackward>)\n",
            "tensor(0.4457, grad_fn=<NegBackward>)\n",
            "tensor(0.3041, grad_fn=<NegBackward>)\n",
            "tensor(0.5530, grad_fn=<NegBackward>)\n",
            "tensor(0.2778, grad_fn=<NegBackward>)\n",
            "tensor(0.3682, grad_fn=<NegBackward>)\n",
            "tensor(0.2593, grad_fn=<NegBackward>)\n",
            "tensor(0.2848, grad_fn=<NegBackward>)\n",
            "tensor(0.2270, grad_fn=<NegBackward>)\n",
            "tensor(0.2355, grad_fn=<NegBackward>)\n",
            "tensor(0.3261, grad_fn=<NegBackward>)\n",
            "tensor(0.3824, grad_fn=<NegBackward>)\n",
            "tensor(0.4196, grad_fn=<NegBackward>)\n",
            "tensor(0.3587, grad_fn=<NegBackward>)\n",
            "tensor(0.3054, grad_fn=<NegBackward>)\n",
            "tensor(0.2831, grad_fn=<NegBackward>)\n",
            "tensor(0.1796, grad_fn=<NegBackward>)\n",
            "tensor(0.1875, grad_fn=<NegBackward>)\n",
            "tensor(0.3924, grad_fn=<NegBackward>)\n",
            "tensor(0.1517, grad_fn=<NegBackward>)\n",
            "tensor(0.1009, grad_fn=<NegBackward>)\n",
            "tensor(0.1693, grad_fn=<NegBackward>)\n",
            "tensor(0.1928, grad_fn=<NegBackward>)\n",
            "tensor(0.2757, grad_fn=<NegBackward>)\n",
            "tensor(0.2007, grad_fn=<NegBackward>)\n",
            "tensor(0.2364, grad_fn=<NegBackward>)\n",
            "tensor(0.1991, grad_fn=<NegBackward>)\n",
            "tensor(0.1988, grad_fn=<NegBackward>)\n",
            "tensor(0.3210, grad_fn=<NegBackward>)\n",
            "tensor(0.4740, grad_fn=<NegBackward>)\n",
            "tensor(0.5278, grad_fn=<NegBackward>)\n",
            "tensor(0.3312, grad_fn=<NegBackward>)\n",
            "tensor(0.4806, grad_fn=<NegBackward>)\n",
            "tensor(0.4311, grad_fn=<NegBackward>)\n",
            "tensor(0.3721, grad_fn=<NegBackward>)\n",
            "tensor(0.5339, grad_fn=<NegBackward>)\n",
            "tensor(0.3264, grad_fn=<NegBackward>)\n",
            "tensor(0.1748, grad_fn=<NegBackward>)\n",
            "tensor(0.2936, grad_fn=<NegBackward>)\n",
            "tensor(0.1906, grad_fn=<NegBackward>)\n",
            "tensor(0.2867, grad_fn=<NegBackward>)\n",
            "tensor(0.3633, grad_fn=<NegBackward>)\n",
            "tensor(0.2132, grad_fn=<NegBackward>)\n",
            "tensor(0.2072, grad_fn=<NegBackward>)\n",
            "tensor(0.3110, grad_fn=<NegBackward>)\n",
            "tensor(0.4824, grad_fn=<NegBackward>)\n",
            "tensor(0.1875, grad_fn=<NegBackward>)\n",
            "tensor(0.3342, grad_fn=<NegBackward>)\n",
            "tensor(0.2679, grad_fn=<NegBackward>)\n",
            "tensor(0.1905, grad_fn=<NegBackward>)\n",
            "tensor(0.1668, grad_fn=<NegBackward>)\n",
            "tensor(0.2817, grad_fn=<NegBackward>)\n",
            "tensor(0.3098, grad_fn=<NegBackward>)\n",
            "tensor(0.3986, grad_fn=<NegBackward>)\n",
            "tensor(0.3849, grad_fn=<NegBackward>)\n",
            "tensor(0.3166, grad_fn=<NegBackward>)\n",
            "tensor(0.2653, grad_fn=<NegBackward>)\n",
            "tensor(0.2361, grad_fn=<NegBackward>)\n",
            "tensor(0.1156, grad_fn=<NegBackward>)\n",
            "tensor(0.3017, grad_fn=<NegBackward>)\n",
            "tensor(0.3877, grad_fn=<NegBackward>)\n",
            "tensor(0.1958, grad_fn=<NegBackward>)\n",
            "tensor(0.2633, grad_fn=<NegBackward>)\n",
            "tensor(0.1492, grad_fn=<NegBackward>)\n",
            "tensor(0.1905, grad_fn=<NegBackward>)\n",
            "tensor(0.3350, grad_fn=<NegBackward>)\n",
            "tensor(0.3082, grad_fn=<NegBackward>)\n",
            "tensor(0.3017, grad_fn=<NegBackward>)\n",
            "tensor(0.1846, grad_fn=<NegBackward>)\n",
            "tensor(0.3073, grad_fn=<NegBackward>)\n",
            "tensor(0.4543, grad_fn=<NegBackward>)\n",
            "tensor(0.4416, grad_fn=<NegBackward>)\n",
            "tensor(0.2642, grad_fn=<NegBackward>)\n",
            "tensor(0.6562, grad_fn=<NegBackward>)\n",
            "tensor(0.7037, grad_fn=<NegBackward>)\n",
            "tensor(0.9334, grad_fn=<NegBackward>)\n",
            "tensor(0.5401, grad_fn=<NegBackward>)\n",
            "tensor(0.5236, grad_fn=<NegBackward>)\n",
            "tensor(0.2669, grad_fn=<NegBackward>)\n",
            "tensor(0.2842, grad_fn=<NegBackward>)\n",
            "tensor(0.5015, grad_fn=<NegBackward>)\n",
            "tensor(0.2937, grad_fn=<NegBackward>)\n",
            "tensor(0.3606, grad_fn=<NegBackward>)\n",
            "tensor(0.2780, grad_fn=<NegBackward>)\n",
            "tensor(0.4092, grad_fn=<NegBackward>)\n",
            "tensor(0.3126, grad_fn=<NegBackward>)\n",
            "tensor(0.2178, grad_fn=<NegBackward>)\n",
            "tensor(0.1960, grad_fn=<NegBackward>)\n",
            "tensor(0.4094, grad_fn=<NegBackward>)\n",
            "tensor(0.3297, grad_fn=<NegBackward>)\n",
            "tensor(0.3504, grad_fn=<NegBackward>)\n",
            "tensor(0.2625, grad_fn=<NegBackward>)\n",
            "tensor(0.3628, grad_fn=<NegBackward>)\n",
            "tensor(0.4275, grad_fn=<NegBackward>)\n",
            "tensor(0.4770, grad_fn=<NegBackward>)\n",
            "tensor(0.3496, grad_fn=<NegBackward>)\n",
            "tensor(0.3004, grad_fn=<NegBackward>)\n",
            "tensor(0.1849, grad_fn=<NegBackward>)\n",
            "tensor(0.1736, grad_fn=<NegBackward>)\n",
            "tensor(0.1904, grad_fn=<NegBackward>)\n",
            "tensor(0.2395, grad_fn=<NegBackward>)\n",
            "tensor(0.1643, grad_fn=<NegBackward>)\n",
            "tensor(0.2973, grad_fn=<NegBackward>)\n",
            "tensor(0.2473, grad_fn=<NegBackward>)\n",
            "tensor(0.2828, grad_fn=<NegBackward>)\n",
            "tensor(0.8305, grad_fn=<NegBackward>)\n",
            "tensor(0.4051, grad_fn=<NegBackward>)\n",
            "tensor(0.5682, grad_fn=<NegBackward>)\n",
            "tensor(0.2718, grad_fn=<NegBackward>)\n",
            "tensor(0.2545, grad_fn=<NegBackward>)\n",
            "tensor(0.3418, grad_fn=<NegBackward>)\n",
            "tensor(0.2855, grad_fn=<NegBackward>)\n",
            "tensor(0.3871, grad_fn=<NegBackward>)\n",
            "tensor(0.2567, grad_fn=<NegBackward>)\n",
            "tensor(0.3295, grad_fn=<NegBackward>)\n",
            "tensor(0.4649, grad_fn=<NegBackward>)\n",
            "tensor(0.2370, grad_fn=<NegBackward>)\n",
            "tensor(0.3506, grad_fn=<NegBackward>)\n",
            "tensor(0.3044, grad_fn=<NegBackward>)\n",
            "tensor(0.2187, grad_fn=<NegBackward>)\n",
            "tensor(0.2850, grad_fn=<NegBackward>)\n",
            "tensor(0.2892, grad_fn=<NegBackward>)\n",
            "tensor(0.2406, grad_fn=<NegBackward>)\n",
            "tensor(0.4114, grad_fn=<NegBackward>)\n",
            "tensor(0.3415, grad_fn=<NegBackward>)\n",
            "tensor(0.3095, grad_fn=<NegBackward>)\n",
            "tensor(0.3066, grad_fn=<NegBackward>)\n",
            "tensor(0.3724, grad_fn=<NegBackward>)\n",
            "tensor(0.2077, grad_fn=<NegBackward>)\n",
            "tensor(0.1787, grad_fn=<NegBackward>)\n",
            "tensor(0.2193, grad_fn=<NegBackward>)\n",
            "tensor(0.4911, grad_fn=<NegBackward>)\n",
            "tensor(0.2620, grad_fn=<NegBackward>)\n",
            "tensor(0.2961, grad_fn=<NegBackward>)\n",
            "tensor(0.2293, grad_fn=<NegBackward>)\n",
            "tensor(0.3546, grad_fn=<NegBackward>)\n",
            "tensor(0.5239, grad_fn=<NegBackward>)\n",
            "tensor(0.3278, grad_fn=<NegBackward>)\n",
            "tensor(0.6351, grad_fn=<NegBackward>)\n",
            "tensor(0.4215, grad_fn=<NegBackward>)\n",
            "tensor(0.4688, grad_fn=<NegBackward>)\n",
            "tensor(0.2354, grad_fn=<NegBackward>)\n",
            "tensor(0.2254, grad_fn=<NegBackward>)\n",
            "tensor(0.3178, grad_fn=<NegBackward>)\n",
            "tensor(0.2381, grad_fn=<NegBackward>)\n",
            "tensor(0.2104, grad_fn=<NegBackward>)\n",
            "tensor(0.3539, grad_fn=<NegBackward>)\n",
            "tensor(0.5234, grad_fn=<NegBackward>)\n",
            "tensor(0.2720, grad_fn=<NegBackward>)\n",
            "tensor(0.3556, grad_fn=<NegBackward>)\n",
            "tensor(0.3475, grad_fn=<NegBackward>)\n",
            "tensor(0.1690, grad_fn=<NegBackward>)\n",
            "tensor(0.7150, grad_fn=<NegBackward>)\n",
            "tensor(0.2524, grad_fn=<NegBackward>)\n",
            "tensor(0.6606, grad_fn=<NegBackward>)\n",
            "tensor(0.6167, grad_fn=<NegBackward>)\n",
            "tensor(0.1648, grad_fn=<NegBackward>)\n",
            "tensor(0.2688, grad_fn=<NegBackward>)\n",
            "tensor(0.3450, grad_fn=<NegBackward>)\n",
            "tensor(0.3614, grad_fn=<NegBackward>)\n",
            "tensor(0.3789, grad_fn=<NegBackward>)\n",
            "tensor(0.4730, grad_fn=<NegBackward>)\n",
            "tensor(0.4450, grad_fn=<NegBackward>)\n",
            "tensor(0.2878, grad_fn=<NegBackward>)\n",
            "tensor(0.3469, grad_fn=<NegBackward>)\n",
            "tensor(0.2717, grad_fn=<NegBackward>)\n",
            "tensor(0.4718, grad_fn=<NegBackward>)\n",
            "tensor(0.1161, grad_fn=<NegBackward>)\n",
            "tensor(0.2191, grad_fn=<NegBackward>)\n",
            "tensor(0.1602, grad_fn=<NegBackward>)\n",
            "tensor(0.1671, grad_fn=<NegBackward>)\n",
            "tensor(0.3518, grad_fn=<NegBackward>)\n",
            "tensor(0.1589, grad_fn=<NegBackward>)\n",
            "tensor(0.4121, grad_fn=<NegBackward>)\n",
            "tensor(0.1500, grad_fn=<NegBackward>)\n",
            "tensor(0.3337, grad_fn=<NegBackward>)\n",
            "tensor(0.4226, grad_fn=<NegBackward>)\n",
            "tensor(0.3913, grad_fn=<NegBackward>)\n",
            "tensor(0.2648, grad_fn=<NegBackward>)\n",
            "tensor(0.2496, grad_fn=<NegBackward>)\n",
            "tensor(0.4574, grad_fn=<NegBackward>)\n",
            "tensor(0.2103, grad_fn=<NegBackward>)\n",
            "tensor(0.4013, grad_fn=<NegBackward>)\n",
            "tensor(0.4000, grad_fn=<NegBackward>)\n",
            "tensor(0.4123, grad_fn=<NegBackward>)\n",
            "tensor(0.4785, grad_fn=<NegBackward>)\n",
            "tensor(0.2856, grad_fn=<NegBackward>)\n",
            "tensor(0.2162, grad_fn=<NegBackward>)\n",
            "tensor(0.1675, grad_fn=<NegBackward>)\n",
            "tensor(0.2020, grad_fn=<NegBackward>)\n",
            "tensor(0.2773, grad_fn=<NegBackward>)\n",
            "tensor(0.3764, grad_fn=<NegBackward>)\n",
            "tensor(0.5226, grad_fn=<NegBackward>)\n",
            "tensor(0.3394, grad_fn=<NegBackward>)\n",
            "tensor(0.5126, grad_fn=<NegBackward>)\n",
            "tensor(0.4944, grad_fn=<NegBackward>)\n",
            "tensor(0.3740, grad_fn=<NegBackward>)\n",
            "tensor(0.2829, grad_fn=<NegBackward>)\n",
            "tensor(0.2489, grad_fn=<NegBackward>)\n",
            "tensor(0.0980, grad_fn=<NegBackward>)\n",
            "tensor(0.3733, grad_fn=<NegBackward>)\n",
            "tensor(0.6416, grad_fn=<NegBackward>)\n",
            "tensor(0.3393, grad_fn=<NegBackward>)\n",
            "tensor(0.4547, grad_fn=<NegBackward>)\n",
            "tensor(0.2759, grad_fn=<NegBackward>)\n",
            "tensor(0.2257, grad_fn=<NegBackward>)\n",
            "tensor(0.5182, grad_fn=<NegBackward>)\n",
            "tensor(0.3981, grad_fn=<NegBackward>)\n",
            "tensor(0.3986, grad_fn=<NegBackward>)\n",
            "tensor(0.3603, grad_fn=<NegBackward>)\n",
            "tensor(0.4074, grad_fn=<NegBackward>)\n",
            "tensor(0.4795, grad_fn=<NegBackward>)\n",
            "tensor(0.2855, grad_fn=<NegBackward>)\n",
            "tensor(0.5215, grad_fn=<NegBackward>)\n",
            "tensor(0.6514, grad_fn=<NegBackward>)\n",
            "tensor(0.3853, grad_fn=<NegBackward>)\n",
            "tensor(0.5001, grad_fn=<NegBackward>)\n",
            "tensor(0.1585, grad_fn=<NegBackward>)\n",
            "tensor(0.1628, grad_fn=<NegBackward>)\n",
            "tensor(0.2885, grad_fn=<NegBackward>)\n",
            "tensor(0.1355, grad_fn=<NegBackward>)\n",
            "tensor(0.4228, grad_fn=<NegBackward>)\n",
            "tensor(0.1082, grad_fn=<NegBackward>)\n",
            "tensor(0.2258, grad_fn=<NegBackward>)\n",
            "tensor(0.2607, grad_fn=<NegBackward>)\n",
            "tensor(0.3173, grad_fn=<NegBackward>)\n",
            "tensor(0.2024, grad_fn=<NegBackward>)\n",
            "tensor(0.2426, grad_fn=<NegBackward>)\n",
            "tensor(0.3113, grad_fn=<NegBackward>)\n",
            "tensor(0.4357, grad_fn=<NegBackward>)\n",
            "tensor(0.3603, grad_fn=<NegBackward>)\n",
            "tensor(0.3248, grad_fn=<NegBackward>)\n",
            "tensor(0.4114, grad_fn=<NegBackward>)\n",
            "tensor(0.1680, grad_fn=<NegBackward>)\n",
            "tensor(0.6250, grad_fn=<NegBackward>)\n",
            "tensor(0.2374, grad_fn=<NegBackward>)\n",
            "tensor(0.3729, grad_fn=<NegBackward>)\n",
            "tensor(0.3683, grad_fn=<NegBackward>)\n",
            "tensor(0.1773, grad_fn=<NegBackward>)\n",
            "tensor(0.4081, grad_fn=<NegBackward>)\n",
            "tensor(0.4504, grad_fn=<NegBackward>)\n",
            "tensor(0.2111, grad_fn=<NegBackward>)\n",
            "tensor(0.3040, grad_fn=<NegBackward>)\n",
            "tensor(0.1366, grad_fn=<NegBackward>)\n",
            "tensor(0.1433, grad_fn=<NegBackward>)\n",
            "tensor(0.2022, grad_fn=<NegBackward>)\n",
            "tensor(0.5997, grad_fn=<NegBackward>)\n",
            "tensor(0.2555, grad_fn=<NegBackward>)\n",
            "tensor(0.1650, grad_fn=<NegBackward>)\n",
            "tensor(0.3251, grad_fn=<NegBackward>)\n",
            "tensor(0.2274, grad_fn=<NegBackward>)\n",
            "tensor(0.3065, grad_fn=<NegBackward>)\n",
            "tensor(0.1721, grad_fn=<NegBackward>)\n",
            "tensor(0.1751, grad_fn=<NegBackward>)\n",
            "tensor(0.2481, grad_fn=<NegBackward>)\n",
            "tensor(0.5833, grad_fn=<NegBackward>)\n",
            "tensor(0.6574, grad_fn=<NegBackward>)\n",
            "tensor(0.4549, grad_fn=<NegBackward>)\n",
            "tensor(0.2709, grad_fn=<NegBackward>)\n",
            "tensor(0.4412, grad_fn=<NegBackward>)\n",
            "tensor(0.2561, grad_fn=<NegBackward>)\n",
            "tensor(0.2076, grad_fn=<NegBackward>)\n",
            "tensor(0.1268, grad_fn=<NegBackward>)\n",
            "tensor(0.3113, grad_fn=<NegBackward>)\n",
            "tensor(0.6895, grad_fn=<NegBackward>)\n",
            "tensor(0.5881, grad_fn=<NegBackward>)\n",
            "tensor(0.5726, grad_fn=<NegBackward>)\n",
            "tensor(0.2943, grad_fn=<NegBackward>)\n",
            "tensor(0.2194, grad_fn=<NegBackward>)\n",
            "tensor(0.3417, grad_fn=<NegBackward>)\n",
            "tensor(0.6201, grad_fn=<NegBackward>)\n",
            "tensor(0.2296, grad_fn=<NegBackward>)\n",
            "tensor(0.3908, grad_fn=<NegBackward>)\n",
            "tensor(0.2763, grad_fn=<NegBackward>)\n",
            "tensor(0.2076, grad_fn=<NegBackward>)\n",
            "tensor(0.4695, grad_fn=<NegBackward>)\n",
            "tensor(0.3182, grad_fn=<NegBackward>)\n",
            "tensor(0.3695, grad_fn=<NegBackward>)\n",
            "tensor(0.1303, grad_fn=<NegBackward>)\n",
            "tensor(0.2019, grad_fn=<NegBackward>)\n",
            "tensor(0.4792, grad_fn=<NegBackward>)\n",
            "tensor(0.2186, grad_fn=<NegBackward>)\n",
            "tensor(0.4277, grad_fn=<NegBackward>)\n",
            "tensor(0.3444, grad_fn=<NegBackward>)\n",
            "tensor(0.2175, grad_fn=<NegBackward>)\n",
            "tensor(0.3148, grad_fn=<NegBackward>)\n",
            "tensor(0.5577, grad_fn=<NegBackward>)\n",
            "tensor(0.3981, grad_fn=<NegBackward>)\n",
            "tensor(0.2897, grad_fn=<NegBackward>)\n",
            "tensor(0.6076, grad_fn=<NegBackward>)\n",
            "tensor(0.6367, grad_fn=<NegBackward>)\n",
            "tensor(0.0908, grad_fn=<NegBackward>)\n",
            "tensor(0.5457, grad_fn=<NegBackward>)\n",
            "tensor(0.3730, grad_fn=<NegBackward>)\n",
            "tensor(0.6842, grad_fn=<NegBackward>)\n",
            "tensor(0.2395, grad_fn=<NegBackward>)\n",
            "tensor(0.3005, grad_fn=<NegBackward>)\n",
            "tensor(0.3425, grad_fn=<NegBackward>)\n",
            "tensor(0.1902, grad_fn=<NegBackward>)\n",
            "tensor(0.2354, grad_fn=<NegBackward>)\n",
            "tensor(0.2080, grad_fn=<NegBackward>)\n",
            "tensor(0.2725, grad_fn=<NegBackward>)\n",
            "tensor(0.1172, grad_fn=<NegBackward>)\n",
            "tensor(0.2122, grad_fn=<NegBackward>)\n",
            "tensor(0.2743, grad_fn=<NegBackward>)\n",
            "tensor(0.3287, grad_fn=<NegBackward>)\n",
            "tensor(0.1674, grad_fn=<NegBackward>)\n",
            "tensor(0.3115, grad_fn=<NegBackward>)\n",
            "tensor(0.1373, grad_fn=<NegBackward>)\n",
            "tensor(0.1619, grad_fn=<NegBackward>)\n",
            "tensor(0.3367, grad_fn=<NegBackward>)\n",
            "tensor(0.1388, grad_fn=<NegBackward>)\n",
            "tensor(0.1166, grad_fn=<NegBackward>)\n",
            "tensor(0.2024, grad_fn=<NegBackward>)\n",
            "tensor(0.4176, grad_fn=<NegBackward>)\n",
            "tensor(0.2713, grad_fn=<NegBackward>)\n",
            "tensor(0.3450, grad_fn=<NegBackward>)\n",
            "tensor(0.2218, grad_fn=<NegBackward>)\n",
            "tensor(0.2063, grad_fn=<NegBackward>)\n",
            "tensor(0.2477, grad_fn=<NegBackward>)\n",
            "tensor(0.4032, grad_fn=<NegBackward>)\n",
            "tensor(0.2317, grad_fn=<NegBackward>)\n",
            "tensor(0.1560, grad_fn=<NegBackward>)\n",
            "tensor(0.3329, grad_fn=<NegBackward>)\n",
            "tensor(0.2961, grad_fn=<NegBackward>)\n",
            "tensor(0.2279, grad_fn=<NegBackward>)\n",
            "tensor(0.2115, grad_fn=<NegBackward>)\n",
            "tensor(0.2512, grad_fn=<NegBackward>)\n",
            "tensor(0.2522, grad_fn=<NegBackward>)\n",
            "tensor(0.1181, grad_fn=<NegBackward>)\n",
            "tensor(0.5036, grad_fn=<NegBackward>)\n",
            "tensor(0.4129, grad_fn=<NegBackward>)\n",
            "tensor(0.3602, grad_fn=<NegBackward>)\n",
            "tensor(0.1358, grad_fn=<NegBackward>)\n",
            "tensor(0.1183, grad_fn=<NegBackward>)\n",
            "tensor(0.2987, grad_fn=<NegBackward>)\n",
            "tensor(0.4189, grad_fn=<NegBackward>)\n",
            "tensor(0.4083, grad_fn=<NegBackward>)\n",
            "tensor(0.3492, grad_fn=<NegBackward>)\n",
            "tensor(0.3100, grad_fn=<NegBackward>)\n",
            "tensor(0.2127, grad_fn=<NegBackward>)\n",
            "tensor(0.2373, grad_fn=<NegBackward>)\n",
            "tensor(0.2096, grad_fn=<NegBackward>)\n",
            "tensor(0.2626, grad_fn=<NegBackward>)\n",
            "tensor(0.1162, grad_fn=<NegBackward>)\n",
            "tensor(0.3620, grad_fn=<NegBackward>)\n",
            "tensor(0.2064, grad_fn=<NegBackward>)\n",
            "tensor(0.3048, grad_fn=<NegBackward>)\n",
            "tensor(0.2993, grad_fn=<NegBackward>)\n",
            "tensor(0.1784, grad_fn=<NegBackward>)\n",
            "tensor(0.5021, grad_fn=<NegBackward>)\n",
            "tensor(0.2827, grad_fn=<NegBackward>)\n",
            "tensor(0.2552, grad_fn=<NegBackward>)\n",
            "tensor(0.6277, grad_fn=<NegBackward>)\n",
            "tensor(0.2132, grad_fn=<NegBackward>)\n",
            "tensor(0.3650, grad_fn=<NegBackward>)\n",
            "tensor(0.2577, grad_fn=<NegBackward>)\n",
            "tensor(0.2346, grad_fn=<NegBackward>)\n",
            "tensor(0.1001, grad_fn=<NegBackward>)\n",
            "tensor(0.3644, grad_fn=<NegBackward>)\n",
            "tensor(0.2511, grad_fn=<NegBackward>)\n",
            "tensor(0.3134, grad_fn=<NegBackward>)\n",
            "tensor(0.2907, grad_fn=<NegBackward>)\n",
            "tensor(0.2201, grad_fn=<NegBackward>)\n",
            "tensor(0.3603, grad_fn=<NegBackward>)\n",
            "tensor(0.2779, grad_fn=<NegBackward>)\n",
            "tensor(0.2431, grad_fn=<NegBackward>)\n",
            "tensor(0.1589, grad_fn=<NegBackward>)\n",
            "tensor(0.3350, grad_fn=<NegBackward>)\n",
            "tensor(0.1291, grad_fn=<NegBackward>)\n",
            "tensor(0.1982, grad_fn=<NegBackward>)\n",
            "tensor(0.1383, grad_fn=<NegBackward>)\n",
            "tensor(0.1507, grad_fn=<NegBackward>)\n",
            "tensor(0.2562, grad_fn=<NegBackward>)\n",
            "tensor(0.3829, grad_fn=<NegBackward>)\n",
            "tensor(0.1704, grad_fn=<NegBackward>)\n",
            "tensor(0.2083, grad_fn=<NegBackward>)\n",
            "tensor(0.2085, grad_fn=<NegBackward>)\n",
            "tensor(0.1642, grad_fn=<NegBackward>)\n",
            "tensor(0.3907, grad_fn=<NegBackward>)\n",
            "tensor(0.4248, grad_fn=<NegBackward>)\n",
            "tensor(0.4753, grad_fn=<NegBackward>)\n",
            "tensor(0.5755, grad_fn=<NegBackward>)\n",
            "tensor(0.2208, grad_fn=<NegBackward>)\n",
            "tensor(0.3522, grad_fn=<NegBackward>)\n",
            "tensor(0.3736, grad_fn=<NegBackward>)\n",
            "tensor(0.4238, grad_fn=<NegBackward>)\n",
            "tensor(0.4366, grad_fn=<NegBackward>)\n",
            "tensor(0.1847, grad_fn=<NegBackward>)\n",
            "tensor(0.2102, grad_fn=<NegBackward>)\n",
            "tensor(0.3114, grad_fn=<NegBackward>)\n",
            "tensor(0.2098, grad_fn=<NegBackward>)\n",
            "tensor(0.3097, grad_fn=<NegBackward>)\n",
            "tensor(0.2527, grad_fn=<NegBackward>)\n",
            "tensor(0.2628, grad_fn=<NegBackward>)\n",
            "tensor(0.4906, grad_fn=<NegBackward>)\n",
            "tensor(0.4018, grad_fn=<NegBackward>)\n",
            "tensor(0.2532, grad_fn=<NegBackward>)\n",
            "tensor(0.2190, grad_fn=<NegBackward>)\n",
            "tensor(0.4183, grad_fn=<NegBackward>)\n",
            "tensor(0.1740, grad_fn=<NegBackward>)\n",
            "tensor(0.5747, grad_fn=<NegBackward>)\n",
            "tensor(0.3329, grad_fn=<NegBackward>)\n",
            "tensor(0.1625, grad_fn=<NegBackward>)\n",
            "tensor(0.3060, grad_fn=<NegBackward>)\n",
            "tensor(0.5359, grad_fn=<NegBackward>)\n",
            "tensor(0.2506, grad_fn=<NegBackward>)\n",
            "tensor(0.2567, grad_fn=<NegBackward>)\n",
            "tensor(0.5399, grad_fn=<NegBackward>)\n",
            "tensor(0.7840, grad_fn=<NegBackward>)\n",
            "tensor(0.5133, grad_fn=<NegBackward>)\n",
            "tensor(0.5449, grad_fn=<NegBackward>)\n",
            "tensor(0.4019, grad_fn=<NegBackward>)\n",
            "tensor(0.2374, grad_fn=<NegBackward>)\n",
            "tensor(0.1387, grad_fn=<NegBackward>)\n",
            "tensor(0.4266, grad_fn=<NegBackward>)\n",
            "tensor(0.2351, grad_fn=<NegBackward>)\n",
            "tensor(0.3952, grad_fn=<NegBackward>)\n",
            "tensor(0.3244, grad_fn=<NegBackward>)\n",
            "tensor(0.3612, grad_fn=<NegBackward>)\n",
            "tensor(0.5089, grad_fn=<NegBackward>)\n",
            "tensor(0.2584, grad_fn=<NegBackward>)\n",
            "tensor(0.3697, grad_fn=<NegBackward>)\n",
            "tensor(0.2044, grad_fn=<NegBackward>)\n",
            "tensor(0.0875, grad_fn=<NegBackward>)\n",
            "tensor(0.4455, grad_fn=<NegBackward>)\n",
            "tensor(0.1101, grad_fn=<NegBackward>)\n",
            "tensor(0.1750, grad_fn=<NegBackward>)\n",
            "tensor(0.2566, grad_fn=<NegBackward>)\n",
            "tensor(0.3477, grad_fn=<NegBackward>)\n",
            "tensor(0.1866, grad_fn=<NegBackward>)\n",
            "tensor(0.2242, grad_fn=<NegBackward>)\n",
            "tensor(0.5005, grad_fn=<NegBackward>)\n",
            "tensor(0.2330, grad_fn=<NegBackward>)\n",
            "tensor(0.2177, grad_fn=<NegBackward>)\n",
            "tensor(0.1476, grad_fn=<NegBackward>)\n",
            "tensor(0.2125, grad_fn=<NegBackward>)\n",
            "tensor(0.0944, grad_fn=<NegBackward>)\n",
            "tensor(0.1244, grad_fn=<NegBackward>)\n",
            "tensor(0.2199, grad_fn=<NegBackward>)\n",
            "tensor(0.3985, grad_fn=<NegBackward>)\n",
            "tensor(0.2807, grad_fn=<NegBackward>)\n",
            "tensor(0.2405, grad_fn=<NegBackward>)\n",
            "tensor(0.2116, grad_fn=<NegBackward>)\n",
            "tensor(0.2744, grad_fn=<NegBackward>)\n",
            "tensor(0.2383, grad_fn=<NegBackward>)\n",
            "tensor(0.1644, grad_fn=<NegBackward>)\n",
            "tensor(0.1333, grad_fn=<NegBackward>)\n",
            "tensor(0.3351, grad_fn=<NegBackward>)\n",
            "tensor(0.1481, grad_fn=<NegBackward>)\n",
            "tensor(0.2049, grad_fn=<NegBackward>)\n",
            "tensor(0.2348, grad_fn=<NegBackward>)\n",
            "tensor(0.2799, grad_fn=<NegBackward>)\n",
            "tensor(0.5627, grad_fn=<NegBackward>)\n",
            "tensor(0.4167, grad_fn=<NegBackward>)\n",
            "tensor(0.5520, grad_fn=<NegBackward>)\n",
            "tensor(0.4527, grad_fn=<NegBackward>)\n",
            "tensor(0.1884, grad_fn=<NegBackward>)\n",
            "tensor(0.3288, grad_fn=<NegBackward>)\n",
            "tensor(0.2096, grad_fn=<NegBackward>)\n",
            "tensor(0.2146, grad_fn=<NegBackward>)\n",
            "tensor(0.3185, grad_fn=<NegBackward>)\n",
            "tensor(0.2136, grad_fn=<NegBackward>)\n",
            "tensor(0.4716, grad_fn=<NegBackward>)\n",
            "tensor(0.2651, grad_fn=<NegBackward>)\n",
            "tensor(0.3033, grad_fn=<NegBackward>)\n",
            "tensor(0.3511, grad_fn=<NegBackward>)\n",
            "tensor(0.3033, grad_fn=<NegBackward>)\n",
            "tensor(0.3983, grad_fn=<NegBackward>)\n",
            "tensor(0.6253, grad_fn=<NegBackward>)\n",
            "tensor(0.6495, grad_fn=<NegBackward>)\n",
            "tensor(0.5096, grad_fn=<NegBackward>)\n",
            "tensor(0.3390, grad_fn=<NegBackward>)\n",
            "tensor(0.1944, grad_fn=<NegBackward>)\n",
            "tensor(0.2498, grad_fn=<NegBackward>)\n",
            "tensor(0.5189, grad_fn=<NegBackward>)\n",
            "tensor(0.5835, grad_fn=<NegBackward>)\n",
            "tensor(0.4588, grad_fn=<NegBackward>)\n",
            "tensor(0.4025, grad_fn=<NegBackward>)\n",
            "tensor(0.2406, grad_fn=<NegBackward>)\n",
            "tensor(0.2867, grad_fn=<NegBackward>)\n",
            "tensor(0.2633, grad_fn=<NegBackward>)\n",
            "tensor(0.3074, grad_fn=<NegBackward>)\n",
            "tensor(0.1961, grad_fn=<NegBackward>)\n",
            "tensor(0.3926, grad_fn=<NegBackward>)\n",
            "tensor(0.1230, grad_fn=<NegBackward>)\n",
            "tensor(0.4444, grad_fn=<NegBackward>)\n",
            "tensor(0.4261, grad_fn=<NegBackward>)\n",
            "tensor(0.2086, grad_fn=<NegBackward>)\n",
            "tensor(0.3794, grad_fn=<NegBackward>)\n",
            "tensor(0.2945, grad_fn=<NegBackward>)\n",
            "tensor(0.6197, grad_fn=<NegBackward>)\n",
            "tensor(0.4821, grad_fn=<NegBackward>)\n",
            "tensor(0.3832, grad_fn=<NegBackward>)\n",
            "tensor(0.3409, grad_fn=<NegBackward>)\n",
            "tensor(0.3347, grad_fn=<NegBackward>)\n",
            "tensor(0.3964, grad_fn=<NegBackward>)\n",
            "tensor(0.7669, grad_fn=<NegBackward>)\n",
            "tensor(0.3177, grad_fn=<NegBackward>)\n",
            "tensor(0.2612, grad_fn=<NegBackward>)\n",
            "tensor(0.3979, grad_fn=<NegBackward>)\n",
            "tensor(0.4227, grad_fn=<NegBackward>)\n",
            "tensor(0.4303, grad_fn=<NegBackward>)\n",
            "tensor(0.5911, grad_fn=<NegBackward>)\n",
            "tensor(0.6717, grad_fn=<NegBackward>)\n",
            "tensor(0.2606, grad_fn=<NegBackward>)\n",
            "tensor(0.2265, grad_fn=<NegBackward>)\n",
            "tensor(0.2122, grad_fn=<NegBackward>)\n",
            "tensor(0.2247, grad_fn=<NegBackward>)\n",
            "tensor(0.5544, grad_fn=<NegBackward>)\n",
            "tensor(0.3110, grad_fn=<NegBackward>)\n",
            "tensor(0.2635, grad_fn=<NegBackward>)\n",
            "tensor(0.2293, grad_fn=<NegBackward>)\n",
            "tensor(0.1777, grad_fn=<NegBackward>)\n",
            "tensor(0.2499, grad_fn=<NegBackward>)\n",
            "tensor(0.3033, grad_fn=<NegBackward>)\n",
            "tensor(0.2425, grad_fn=<NegBackward>)\n",
            "tensor(0.1984, grad_fn=<NegBackward>)\n",
            "tensor(0.3459, grad_fn=<NegBackward>)\n",
            "tensor(0.3681, grad_fn=<NegBackward>)\n",
            "tensor(0.2879, grad_fn=<NegBackward>)\n",
            "tensor(0.2322, grad_fn=<NegBackward>)\n",
            "tensor(0.6123, grad_fn=<NegBackward>)\n",
            "tensor(0.4887, grad_fn=<NegBackward>)\n",
            "tensor(0.2177, grad_fn=<NegBackward>)\n",
            "tensor(0.1559, grad_fn=<NegBackward>)\n",
            "tensor(0.2336, grad_fn=<NegBackward>)\n",
            "tensor(0.2719, grad_fn=<NegBackward>)\n",
            "tensor(0.2808, grad_fn=<NegBackward>)\n",
            "tensor(0.1862, grad_fn=<NegBackward>)\n",
            "tensor(0.3009, grad_fn=<NegBackward>)\n",
            "tensor(0.4516, grad_fn=<NegBackward>)\n",
            "tensor(0.3047, grad_fn=<NegBackward>)\n",
            "tensor(0.3544, grad_fn=<NegBackward>)\n",
            "tensor(0.2594, grad_fn=<NegBackward>)\n",
            "tensor(0.3697, grad_fn=<NegBackward>)\n",
            "tensor(0.2549, grad_fn=<NegBackward>)\n",
            "tensor(0.2669, grad_fn=<NegBackward>)\n",
            "tensor(0.3604, grad_fn=<NegBackward>)\n",
            "tensor(0.3370, grad_fn=<NegBackward>)\n",
            "tensor(0.2972, grad_fn=<NegBackward>)\n",
            "tensor(0.3363, grad_fn=<NegBackward>)\n",
            "tensor(0.3945, grad_fn=<NegBackward>)\n",
            "tensor(0.1484, grad_fn=<NegBackward>)\n",
            "tensor(0.3012, grad_fn=<NegBackward>)\n",
            "tensor(0.2314, grad_fn=<NegBackward>)\n",
            "tensor(0.4039, grad_fn=<NegBackward>)\n",
            "tensor(0.5172, grad_fn=<NegBackward>)\n",
            "tensor(0.2325, grad_fn=<NegBackward>)\n",
            "tensor(0.3677, grad_fn=<NegBackward>)\n",
            "tensor(0.3039, grad_fn=<NegBackward>)\n",
            "tensor(0.4762, grad_fn=<NegBackward>)\n",
            "tensor(0.2591, grad_fn=<NegBackward>)\n",
            "tensor(0.2354, grad_fn=<NegBackward>)\n",
            "tensor(0.2521, grad_fn=<NegBackward>)\n",
            "tensor(0.2806, grad_fn=<NegBackward>)\n",
            "tensor(0.1559, grad_fn=<NegBackward>)\n",
            "tensor(0.1450, grad_fn=<NegBackward>)\n",
            "tensor(0.2072, grad_fn=<NegBackward>)\n",
            "tensor(0.2495, grad_fn=<NegBackward>)\n",
            "tensor(0.2644, grad_fn=<NegBackward>)\n",
            "tensor(0.3133, grad_fn=<NegBackward>)\n",
            "tensor(0.2421, grad_fn=<NegBackward>)\n",
            "tensor(0.4143, grad_fn=<NegBackward>)\n",
            "tensor(0.1961, grad_fn=<NegBackward>)\n",
            "tensor(0.3668, grad_fn=<NegBackward>)\n",
            "tensor(0.1360, grad_fn=<NegBackward>)\n",
            "tensor(0.3253, grad_fn=<NegBackward>)\n",
            "tensor(0.1561, grad_fn=<NegBackward>)\n",
            "tensor(0.1801, grad_fn=<NegBackward>)\n",
            "tensor(0.3241, grad_fn=<NegBackward>)\n",
            "tensor(0.3107, grad_fn=<NegBackward>)\n",
            "tensor(0.2207, grad_fn=<NegBackward>)\n",
            "tensor(0.3397, grad_fn=<NegBackward>)\n",
            "tensor(0.2160, grad_fn=<NegBackward>)\n",
            "tensor(0.2847, grad_fn=<NegBackward>)\n",
            "tensor(0.2894, grad_fn=<NegBackward>)\n",
            "tensor(0.3249, grad_fn=<NegBackward>)\n",
            "tensor(0.3397, grad_fn=<NegBackward>)\n",
            "tensor(0.2320, grad_fn=<NegBackward>)\n",
            "tensor(0.1361, grad_fn=<NegBackward>)\n",
            "tensor(0.0949, grad_fn=<NegBackward>)\n",
            "tensor(0.4310, grad_fn=<NegBackward>)\n",
            "tensor(0.1608, grad_fn=<NegBackward>)\n",
            "tensor(0.2812, grad_fn=<NegBackward>)\n",
            "tensor(0.3300, grad_fn=<NegBackward>)\n",
            "tensor(0.3318, grad_fn=<NegBackward>)\n",
            "tensor(0.1955, grad_fn=<NegBackward>)\n",
            "tensor(0.5268, grad_fn=<NegBackward>)\n",
            "tensor(0.2037, grad_fn=<NegBackward>)\n",
            "tensor(0.2595, grad_fn=<NegBackward>)\n",
            "tensor(0.1654, grad_fn=<NegBackward>)\n",
            "tensor(0.1906, grad_fn=<NegBackward>)\n",
            "tensor(0.1855, grad_fn=<NegBackward>)\n",
            "tensor(0.4025, grad_fn=<NegBackward>)\n",
            "tensor(0.2725, grad_fn=<NegBackward>)\n",
            "tensor(0.5090, grad_fn=<NegBackward>)\n",
            "tensor(0.3595, grad_fn=<NegBackward>)\n",
            "tensor(0.4035, grad_fn=<NegBackward>)\n",
            "tensor(0.6163, grad_fn=<NegBackward>)\n",
            "tensor(0.7094, grad_fn=<NegBackward>)\n",
            "tensor(0.4128, grad_fn=<NegBackward>)\n",
            "tensor(0.3672, grad_fn=<NegBackward>)\n",
            "tensor(0.2883, grad_fn=<NegBackward>)\n",
            "tensor(0.2858, grad_fn=<NegBackward>)\n",
            "tensor(0.1584, grad_fn=<NegBackward>)\n",
            "tensor(0.2827, grad_fn=<NegBackward>)\n",
            "tensor(0.3052, grad_fn=<NegBackward>)\n",
            "tensor(0.0904, grad_fn=<NegBackward>)\n",
            "tensor(0.2071, grad_fn=<NegBackward>)\n",
            "tensor(0.5197, grad_fn=<NegBackward>)\n",
            "tensor(0.2619, grad_fn=<NegBackward>)\n",
            "tensor(0.2440, grad_fn=<NegBackward>)\n",
            "tensor(0.0840, grad_fn=<NegBackward>)\n",
            "tensor(0.1040, grad_fn=<NegBackward>)\n",
            "tensor(0.2695, grad_fn=<NegBackward>)\n",
            "tensor(0.3478, grad_fn=<NegBackward>)\n",
            "tensor(0.1076, grad_fn=<NegBackward>)\n",
            "tensor(0.3622, grad_fn=<NegBackward>)\n",
            "tensor(0.4029, grad_fn=<NegBackward>)\n",
            "tensor(0.4770, grad_fn=<NegBackward>)\n",
            "tensor(0.2861, grad_fn=<NegBackward>)\n",
            "tensor(0.0755, grad_fn=<NegBackward>)\n",
            "tensor(0.2546, grad_fn=<NegBackward>)\n",
            "tensor(0.5324, grad_fn=<NegBackward>)\n",
            "tensor(0.6639, grad_fn=<NegBackward>)\n",
            "tensor(0.4519, grad_fn=<NegBackward>)\n",
            "tensor(0.2525, grad_fn=<NegBackward>)\n",
            "tensor(0.2560, grad_fn=<NegBackward>)\n",
            "tensor(0.2575, grad_fn=<NegBackward>)\n",
            "tensor(0.2167, grad_fn=<NegBackward>)\n",
            "tensor(0.0928, grad_fn=<NegBackward>)\n",
            "tensor(0.2642, grad_fn=<NegBackward>)\n",
            "tensor(0.4339, grad_fn=<NegBackward>)\n",
            "tensor(0.3258, grad_fn=<NegBackward>)\n",
            "tensor(0.3229, grad_fn=<NegBackward>)\n",
            "tensor(0.1250, grad_fn=<NegBackward>)\n",
            "tensor(0.1948, grad_fn=<NegBackward>)\n",
            "tensor(0.2311, grad_fn=<NegBackward>)\n",
            "tensor(0.3250, grad_fn=<NegBackward>)\n",
            "tensor(0.2262, grad_fn=<NegBackward>)\n",
            "tensor(0.2505, grad_fn=<NegBackward>)\n",
            "tensor(0.2352, grad_fn=<NegBackward>)\n",
            "tensor(0.5337, grad_fn=<NegBackward>)\n",
            "tensor(0.1735, grad_fn=<NegBackward>)\n",
            "tensor(0.3639, grad_fn=<NegBackward>)\n",
            "tensor(0.2910, grad_fn=<NegBackward>)\n",
            "tensor(0.4602, grad_fn=<NegBackward>)\n",
            "tensor(0.3393, grad_fn=<NegBackward>)\n",
            "tensor(0.2064, grad_fn=<NegBackward>)\n",
            "tensor(0.1929, grad_fn=<NegBackward>)\n",
            "tensor(0.3125, grad_fn=<NegBackward>)\n",
            "tensor(0.4188, grad_fn=<NegBackward>)\n",
            "tensor(0.1943, grad_fn=<NegBackward>)\n",
            "tensor(0.2304, grad_fn=<NegBackward>)\n",
            "tensor(0.3062, grad_fn=<NegBackward>)\n",
            "tensor(0.4164, grad_fn=<NegBackward>)\n",
            "tensor(0.3356, grad_fn=<NegBackward>)\n",
            "tensor(0.3905, grad_fn=<NegBackward>)\n",
            "tensor(0.2957, grad_fn=<NegBackward>)\n",
            "tensor(0.4644, grad_fn=<NegBackward>)\n",
            "tensor(0.2661, grad_fn=<NegBackward>)\n",
            "tensor(0.3584, grad_fn=<NegBackward>)\n",
            "tensor(0.2886, grad_fn=<NegBackward>)\n",
            "tensor(0.1050, grad_fn=<NegBackward>)\n",
            "tensor(0.3112, grad_fn=<NegBackward>)\n",
            "tensor(0.2906, grad_fn=<NegBackward>)\n",
            "tensor(0.2324, grad_fn=<NegBackward>)\n",
            "tensor(0.4713, grad_fn=<NegBackward>)\n",
            "tensor(0.1009, grad_fn=<NegBackward>)\n",
            "tensor(0.0914, grad_fn=<NegBackward>)\n",
            "tensor(0.2360, grad_fn=<NegBackward>)\n",
            "tensor(0.3247, grad_fn=<NegBackward>)\n",
            "tensor(0.2079, grad_fn=<NegBackward>)\n",
            "tensor(0.2355, grad_fn=<NegBackward>)\n",
            "tensor(0.2294, grad_fn=<NegBackward>)\n",
            "tensor(0.4192, grad_fn=<NegBackward>)\n",
            "tensor(0.1629, grad_fn=<NegBackward>)\n",
            "tensor(0.2301, grad_fn=<NegBackward>)\n",
            "tensor(0.1992, grad_fn=<NegBackward>)\n",
            "tensor(0.2330, grad_fn=<NegBackward>)\n",
            "tensor(0.1716, grad_fn=<NegBackward>)\n",
            "tensor(0.1770, grad_fn=<NegBackward>)\n",
            "tensor(0.3097, grad_fn=<NegBackward>)\n",
            "tensor(0.2853, grad_fn=<NegBackward>)\n",
            "tensor(0.5869, grad_fn=<NegBackward>)\n",
            "tensor(0.3369, grad_fn=<NegBackward>)\n",
            "tensor(0.3711, grad_fn=<NegBackward>)\n",
            "tensor(0.3521, grad_fn=<NegBackward>)\n",
            "tensor(0.5803, grad_fn=<NegBackward>)\n",
            "tensor(0.6151, grad_fn=<NegBackward>)\n",
            "tensor(0.3750, grad_fn=<NegBackward>)\n",
            "tensor(0.3688, grad_fn=<NegBackward>)\n",
            "tensor(0.4870, grad_fn=<NegBackward>)\n",
            "tensor(0.1110, grad_fn=<NegBackward>)\n",
            "tensor(0.1657, grad_fn=<NegBackward>)\n",
            "tensor(0.2200, grad_fn=<NegBackward>)\n",
            "tensor(0.7268, grad_fn=<NegBackward>)\n",
            "tensor(0.3928, grad_fn=<NegBackward>)\n",
            "tensor(0.1641, grad_fn=<NegBackward>)\n",
            "tensor(0.2828, grad_fn=<NegBackward>)\n",
            "tensor(0.2854, grad_fn=<NegBackward>)\n",
            "tensor(0.3867, grad_fn=<NegBackward>)\n",
            "tensor(0.2226, grad_fn=<NegBackward>)\n",
            "tensor(0.3391, grad_fn=<NegBackward>)\n",
            "tensor(0.3088, grad_fn=<NegBackward>)\n",
            "tensor(0.2101, grad_fn=<NegBackward>)\n",
            "tensor(0.3319, grad_fn=<NegBackward>)\n",
            "tensor(0.2424, grad_fn=<NegBackward>)\n",
            "tensor(0.1552, grad_fn=<NegBackward>)\n",
            "tensor(0.1821, grad_fn=<NegBackward>)\n",
            "tensor(0.1483, grad_fn=<NegBackward>)\n",
            "tensor(0.2870, grad_fn=<NegBackward>)\n",
            "tensor(0.2536, grad_fn=<NegBackward>)\n",
            "tensor(0.2154, grad_fn=<NegBackward>)\n",
            "tensor(0.1114, grad_fn=<NegBackward>)\n",
            "tensor(0.7206, grad_fn=<NegBackward>)\n",
            "tensor(0.1933, grad_fn=<NegBackward>)\n",
            "tensor(0.3393, grad_fn=<NegBackward>)\n",
            "tensor(0.3250, grad_fn=<NegBackward>)\n",
            "tensor(0.8249, grad_fn=<NegBackward>)\n",
            "tensor(0.2560, grad_fn=<NegBackward>)\n",
            "tensor(0.2149, grad_fn=<NegBackward>)\n",
            "tensor(0.1780, grad_fn=<NegBackward>)\n",
            "tensor(0.1206, grad_fn=<NegBackward>)\n",
            "tensor(0.2996, grad_fn=<NegBackward>)\n",
            "tensor(0.1309, grad_fn=<NegBackward>)\n",
            "tensor(0.3376, grad_fn=<NegBackward>)\n",
            "tensor(0.4135, grad_fn=<NegBackward>)\n",
            "tensor(0.3860, grad_fn=<NegBackward>)\n",
            "tensor(0.2925, grad_fn=<NegBackward>)\n",
            "tensor(0.2615, grad_fn=<NegBackward>)\n",
            "tensor(0.3025, grad_fn=<NegBackward>)\n",
            "tensor(0.1904, grad_fn=<NegBackward>)\n",
            "tensor(0.2431, grad_fn=<NegBackward>)\n",
            "tensor(0.2488, grad_fn=<NegBackward>)\n",
            "tensor(0.2806, grad_fn=<NegBackward>)\n",
            "tensor(0.4281, grad_fn=<NegBackward>)\n",
            "tensor(0.2056, grad_fn=<NegBackward>)\n",
            "tensor(0.5147, grad_fn=<NegBackward>)\n",
            "tensor(0.4309, grad_fn=<NegBackward>)\n",
            "tensor(0.4295, grad_fn=<NegBackward>)\n",
            "tensor(0.3167, grad_fn=<NegBackward>)\n",
            "tensor(0.3785, grad_fn=<NegBackward>)\n",
            "tensor(0.4159, grad_fn=<NegBackward>)\n",
            "tensor(0.3692, grad_fn=<NegBackward>)\n",
            "tensor(0.2173, grad_fn=<NegBackward>)\n",
            "tensor(0.1583, grad_fn=<NegBackward>)\n",
            "tensor(0.2640, grad_fn=<NegBackward>)\n",
            "tensor(0.3436, grad_fn=<NegBackward>)\n",
            "tensor(0.2645, grad_fn=<NegBackward>)\n",
            "tensor(0.4312, grad_fn=<NegBackward>)\n",
            "tensor(0.3253, grad_fn=<NegBackward>)\n",
            "tensor(0.3510, grad_fn=<NegBackward>)\n",
            "tensor(0.2875, grad_fn=<NegBackward>)\n",
            "tensor(0.4263, grad_fn=<NegBackward>)\n",
            "tensor(0.2486, grad_fn=<NegBackward>)\n",
            "tensor(0.3991, grad_fn=<NegBackward>)\n",
            "tensor(0.3297, grad_fn=<NegBackward>)\n",
            "tensor(0.5078, grad_fn=<NegBackward>)\n",
            "tensor(0.5533, grad_fn=<NegBackward>)\n",
            "tensor(0.3525, grad_fn=<NegBackward>)\n",
            "tensor(0.7211, grad_fn=<NegBackward>)\n",
            "tensor(0.5394, grad_fn=<NegBackward>)\n",
            "tensor(0.3697, grad_fn=<NegBackward>)\n",
            "tensor(0.1423, grad_fn=<NegBackward>)\n",
            "tensor(0.2827, grad_fn=<NegBackward>)\n",
            "tensor(0.4292, grad_fn=<NegBackward>)\n",
            "tensor(0.5966, grad_fn=<NegBackward>)\n",
            "tensor(0.3637, grad_fn=<NegBackward>)\n",
            "tensor(0.2776, grad_fn=<NegBackward>)\n",
            "tensor(0.2708, grad_fn=<NegBackward>)\n",
            "tensor(0.3377, grad_fn=<NegBackward>)\n",
            "tensor(0.3534, grad_fn=<NegBackward>)\n",
            "tensor(0.3278, grad_fn=<NegBackward>)\n",
            "tensor(0.4347, grad_fn=<NegBackward>)\n",
            "tensor(0.3181, grad_fn=<NegBackward>)\n",
            "tensor(0.4503, grad_fn=<NegBackward>)\n",
            "tensor(0.4537, grad_fn=<NegBackward>)\n",
            "tensor(0.4372, grad_fn=<NegBackward>)\n",
            "tensor(0.3953, grad_fn=<NegBackward>)\n",
            "tensor(0.2067, grad_fn=<NegBackward>)\n",
            "tensor(0.1019, grad_fn=<NegBackward>)\n",
            "tensor(0.4519, grad_fn=<NegBackward>)\n",
            "tensor(0.2584, grad_fn=<NegBackward>)\n",
            "tensor(0.5278, grad_fn=<NegBackward>)\n",
            "tensor(0.2615, grad_fn=<NegBackward>)\n",
            "tensor(0.3632, grad_fn=<NegBackward>)\n",
            "tensor(0.2146, grad_fn=<NegBackward>)\n",
            "tensor(0.2544, grad_fn=<NegBackward>)\n",
            "tensor(0.1926, grad_fn=<NegBackward>)\n",
            "tensor(0.1879, grad_fn=<NegBackward>)\n",
            "tensor(0.2796, grad_fn=<NegBackward>)\n",
            "tensor(0.4000, grad_fn=<NegBackward>)\n",
            "tensor(0.3656, grad_fn=<NegBackward>)\n",
            "tensor(0.3231, grad_fn=<NegBackward>)\n",
            "tensor(0.2773, grad_fn=<NegBackward>)\n",
            "tensor(0.2597, grad_fn=<NegBackward>)\n",
            "tensor(0.1575, grad_fn=<NegBackward>)\n",
            "tensor(0.1622, grad_fn=<NegBackward>)\n",
            "tensor(0.3506, grad_fn=<NegBackward>)\n",
            "tensor(0.1116, grad_fn=<NegBackward>)\n",
            "tensor(0.0860, grad_fn=<NegBackward>)\n",
            "tensor(0.1510, grad_fn=<NegBackward>)\n",
            "tensor(0.1736, grad_fn=<NegBackward>)\n",
            "tensor(0.2493, grad_fn=<NegBackward>)\n",
            "tensor(0.1714, grad_fn=<NegBackward>)\n",
            "tensor(0.2003, grad_fn=<NegBackward>)\n",
            "tensor(0.1772, grad_fn=<NegBackward>)\n",
            "tensor(0.1651, grad_fn=<NegBackward>)\n",
            "tensor(0.3085, grad_fn=<NegBackward>)\n",
            "tensor(0.4194, grad_fn=<NegBackward>)\n",
            "tensor(0.4997, grad_fn=<NegBackward>)\n",
            "tensor(0.2947, grad_fn=<NegBackward>)\n",
            "tensor(0.4380, grad_fn=<NegBackward>)\n",
            "tensor(0.3710, grad_fn=<NegBackward>)\n",
            "tensor(0.3535, grad_fn=<NegBackward>)\n",
            "tensor(0.4854, grad_fn=<NegBackward>)\n",
            "tensor(0.2800, grad_fn=<NegBackward>)\n",
            "tensor(0.1584, grad_fn=<NegBackward>)\n",
            "tensor(0.2943, grad_fn=<NegBackward>)\n",
            "tensor(0.1693, grad_fn=<NegBackward>)\n",
            "tensor(0.2567, grad_fn=<NegBackward>)\n",
            "tensor(0.3251, grad_fn=<NegBackward>)\n",
            "tensor(0.1779, grad_fn=<NegBackward>)\n",
            "tensor(0.1896, grad_fn=<NegBackward>)\n",
            "tensor(0.2814, grad_fn=<NegBackward>)\n",
            "tensor(0.4708, grad_fn=<NegBackward>)\n",
            "tensor(0.1696, grad_fn=<NegBackward>)\n",
            "tensor(0.2999, grad_fn=<NegBackward>)\n",
            "tensor(0.2201, grad_fn=<NegBackward>)\n",
            "tensor(0.1644, grad_fn=<NegBackward>)\n",
            "tensor(0.1363, grad_fn=<NegBackward>)\n",
            "tensor(0.2467, grad_fn=<NegBackward>)\n",
            "tensor(0.2773, grad_fn=<NegBackward>)\n",
            "tensor(0.3173, grad_fn=<NegBackward>)\n",
            "tensor(0.3734, grad_fn=<NegBackward>)\n",
            "tensor(0.2788, grad_fn=<NegBackward>)\n",
            "tensor(0.2414, grad_fn=<NegBackward>)\n",
            "tensor(0.2391, grad_fn=<NegBackward>)\n",
            "tensor(0.0962, grad_fn=<NegBackward>)\n",
            "tensor(0.2816, grad_fn=<NegBackward>)\n",
            "tensor(0.3777, grad_fn=<NegBackward>)\n",
            "tensor(0.1748, grad_fn=<NegBackward>)\n",
            "tensor(0.2491, grad_fn=<NegBackward>)\n",
            "tensor(0.1328, grad_fn=<NegBackward>)\n",
            "tensor(0.1740, grad_fn=<NegBackward>)\n",
            "tensor(0.3199, grad_fn=<NegBackward>)\n",
            "tensor(0.2791, grad_fn=<NegBackward>)\n",
            "tensor(0.2660, grad_fn=<NegBackward>)\n",
            "tensor(0.1560, grad_fn=<NegBackward>)\n",
            "tensor(0.2766, grad_fn=<NegBackward>)\n",
            "tensor(0.4362, grad_fn=<NegBackward>)\n",
            "tensor(0.4485, grad_fn=<NegBackward>)\n",
            "tensor(0.2315, grad_fn=<NegBackward>)\n",
            "tensor(0.6046, grad_fn=<NegBackward>)\n",
            "tensor(0.6768, grad_fn=<NegBackward>)\n",
            "tensor(0.9259, grad_fn=<NegBackward>)\n",
            "tensor(0.5457, grad_fn=<NegBackward>)\n",
            "tensor(0.4792, grad_fn=<NegBackward>)\n",
            "tensor(0.2220, grad_fn=<NegBackward>)\n",
            "tensor(0.2748, grad_fn=<NegBackward>)\n",
            "tensor(0.4928, grad_fn=<NegBackward>)\n",
            "tensor(0.2669, grad_fn=<NegBackward>)\n",
            "tensor(0.3392, grad_fn=<NegBackward>)\n",
            "tensor(0.2633, grad_fn=<NegBackward>)\n",
            "tensor(0.4068, grad_fn=<NegBackward>)\n",
            "tensor(0.2766, grad_fn=<NegBackward>)\n",
            "tensor(0.1817, grad_fn=<NegBackward>)\n",
            "tensor(0.1542, grad_fn=<NegBackward>)\n",
            "tensor(0.3760, grad_fn=<NegBackward>)\n",
            "tensor(0.3150, grad_fn=<NegBackward>)\n",
            "tensor(0.3366, grad_fn=<NegBackward>)\n",
            "tensor(0.2263, grad_fn=<NegBackward>)\n",
            "tensor(0.3394, grad_fn=<NegBackward>)\n",
            "tensor(0.3880, grad_fn=<NegBackward>)\n",
            "tensor(0.4541, grad_fn=<NegBackward>)\n",
            "tensor(0.3295, grad_fn=<NegBackward>)\n",
            "tensor(0.2783, grad_fn=<NegBackward>)\n",
            "tensor(0.1493, grad_fn=<NegBackward>)\n",
            "tensor(0.1457, grad_fn=<NegBackward>)\n",
            "tensor(0.1810, grad_fn=<NegBackward>)\n",
            "tensor(0.2024, grad_fn=<NegBackward>)\n",
            "tensor(0.1510, grad_fn=<NegBackward>)\n",
            "tensor(0.2757, grad_fn=<NegBackward>)\n",
            "tensor(0.2278, grad_fn=<NegBackward>)\n",
            "tensor(0.2622, grad_fn=<NegBackward>)\n",
            "tensor(0.8158, grad_fn=<NegBackward>)\n",
            "tensor(0.4019, grad_fn=<NegBackward>)\n",
            "tensor(0.5278, grad_fn=<NegBackward>)\n",
            "tensor(0.2481, grad_fn=<NegBackward>)\n",
            "tensor(0.2168, grad_fn=<NegBackward>)\n",
            "tensor(0.3166, grad_fn=<NegBackward>)\n",
            "tensor(0.2523, grad_fn=<NegBackward>)\n",
            "tensor(0.3308, grad_fn=<NegBackward>)\n",
            "tensor(0.2142, grad_fn=<NegBackward>)\n",
            "tensor(0.2693, grad_fn=<NegBackward>)\n",
            "tensor(0.4382, grad_fn=<NegBackward>)\n",
            "tensor(0.2050, grad_fn=<NegBackward>)\n",
            "tensor(0.3516, grad_fn=<NegBackward>)\n",
            "tensor(0.2757, grad_fn=<NegBackward>)\n",
            "tensor(0.1695, grad_fn=<NegBackward>)\n",
            "tensor(0.2746, grad_fn=<NegBackward>)\n",
            "tensor(0.2850, grad_fn=<NegBackward>)\n",
            "tensor(0.2044, grad_fn=<NegBackward>)\n",
            "tensor(0.3738, grad_fn=<NegBackward>)\n",
            "tensor(0.3158, grad_fn=<NegBackward>)\n",
            "tensor(0.2704, grad_fn=<NegBackward>)\n",
            "tensor(0.2740, grad_fn=<NegBackward>)\n",
            "tensor(0.3702, grad_fn=<NegBackward>)\n",
            "tensor(0.1773, grad_fn=<NegBackward>)\n",
            "tensor(0.1781, grad_fn=<NegBackward>)\n",
            "tensor(0.2058, grad_fn=<NegBackward>)\n",
            "tensor(0.4850, grad_fn=<NegBackward>)\n",
            "tensor(0.2510, grad_fn=<NegBackward>)\n",
            "tensor(0.2755, grad_fn=<NegBackward>)\n",
            "tensor(0.2262, grad_fn=<NegBackward>)\n",
            "tensor(0.3417, grad_fn=<NegBackward>)\n",
            "tensor(0.5054, grad_fn=<NegBackward>)\n",
            "tensor(0.3111, grad_fn=<NegBackward>)\n",
            "tensor(0.6192, grad_fn=<NegBackward>)\n",
            "tensor(0.3822, grad_fn=<NegBackward>)\n",
            "tensor(0.4148, grad_fn=<NegBackward>)\n",
            "tensor(0.2041, grad_fn=<NegBackward>)\n",
            "tensor(0.1954, grad_fn=<NegBackward>)\n",
            "tensor(0.2719, grad_fn=<NegBackward>)\n",
            "tensor(0.2147, grad_fn=<NegBackward>)\n",
            "tensor(0.1851, grad_fn=<NegBackward>)\n",
            "tensor(0.3301, grad_fn=<NegBackward>)\n",
            "tensor(0.5070, grad_fn=<NegBackward>)\n",
            "tensor(0.2404, grad_fn=<NegBackward>)\n",
            "tensor(0.3316, grad_fn=<NegBackward>)\n",
            "tensor(0.3153, grad_fn=<NegBackward>)\n",
            "tensor(0.1469, grad_fn=<NegBackward>)\n",
            "tensor(0.6673, grad_fn=<NegBackward>)\n",
            "tensor(0.2549, grad_fn=<NegBackward>)\n",
            "tensor(0.6727, grad_fn=<NegBackward>)\n",
            "tensor(0.6181, grad_fn=<NegBackward>)\n",
            "tensor(0.1507, grad_fn=<NegBackward>)\n",
            "tensor(0.2405, grad_fn=<NegBackward>)\n",
            "tensor(0.3411, grad_fn=<NegBackward>)\n",
            "tensor(0.3513, grad_fn=<NegBackward>)\n",
            "tensor(0.3855, grad_fn=<NegBackward>)\n",
            "tensor(0.4257, grad_fn=<NegBackward>)\n",
            "tensor(0.4050, grad_fn=<NegBackward>)\n",
            "tensor(0.2629, grad_fn=<NegBackward>)\n",
            "tensor(0.3084, grad_fn=<NegBackward>)\n",
            "tensor(0.2771, grad_fn=<NegBackward>)\n",
            "tensor(0.4509, grad_fn=<NegBackward>)\n",
            "tensor(0.0892, grad_fn=<NegBackward>)\n",
            "tensor(0.2214, grad_fn=<NegBackward>)\n",
            "tensor(0.1332, grad_fn=<NegBackward>)\n",
            "tensor(0.1380, grad_fn=<NegBackward>)\n",
            "tensor(0.3477, grad_fn=<NegBackward>)\n",
            "tensor(0.1271, grad_fn=<NegBackward>)\n",
            "tensor(0.3705, grad_fn=<NegBackward>)\n",
            "tensor(0.1243, grad_fn=<NegBackward>)\n",
            "tensor(0.2805, grad_fn=<NegBackward>)\n",
            "tensor(0.3892, grad_fn=<NegBackward>)\n",
            "tensor(0.3728, grad_fn=<NegBackward>)\n",
            "tensor(0.2600, grad_fn=<NegBackward>)\n",
            "tensor(0.1967, grad_fn=<NegBackward>)\n",
            "tensor(0.4189, grad_fn=<NegBackward>)\n",
            "tensor(0.1727, grad_fn=<NegBackward>)\n",
            "tensor(0.3553, grad_fn=<NegBackward>)\n",
            "tensor(0.3826, grad_fn=<NegBackward>)\n",
            "tensor(0.3718, grad_fn=<NegBackward>)\n",
            "tensor(0.4722, grad_fn=<NegBackward>)\n",
            "tensor(0.2476, grad_fn=<NegBackward>)\n",
            "tensor(0.1914, grad_fn=<NegBackward>)\n",
            "tensor(0.1633, grad_fn=<NegBackward>)\n",
            "tensor(0.1870, grad_fn=<NegBackward>)\n",
            "tensor(0.2351, grad_fn=<NegBackward>)\n",
            "tensor(0.3596, grad_fn=<NegBackward>)\n",
            "tensor(0.5127, grad_fn=<NegBackward>)\n",
            "tensor(0.3201, grad_fn=<NegBackward>)\n",
            "tensor(0.4954, grad_fn=<NegBackward>)\n",
            "tensor(0.4534, grad_fn=<NegBackward>)\n",
            "tensor(0.3525, grad_fn=<NegBackward>)\n",
            "tensor(0.2569, grad_fn=<NegBackward>)\n",
            "tensor(0.2108, grad_fn=<NegBackward>)\n",
            "tensor(0.0803, grad_fn=<NegBackward>)\n",
            "tensor(0.3400, grad_fn=<NegBackward>)\n",
            "tensor(0.6064, grad_fn=<NegBackward>)\n",
            "tensor(0.3074, grad_fn=<NegBackward>)\n",
            "tensor(0.4542, grad_fn=<NegBackward>)\n",
            "tensor(0.2483, grad_fn=<NegBackward>)\n",
            "tensor(0.1998, grad_fn=<NegBackward>)\n",
            "tensor(0.5088, grad_fn=<NegBackward>)\n",
            "tensor(0.3666, grad_fn=<NegBackward>)\n",
            "tensor(0.3679, grad_fn=<NegBackward>)\n",
            "tensor(0.3260, grad_fn=<NegBackward>)\n",
            "tensor(0.3625, grad_fn=<NegBackward>)\n",
            "tensor(0.4483, grad_fn=<NegBackward>)\n",
            "tensor(0.2535, grad_fn=<NegBackward>)\n",
            "tensor(0.5188, grad_fn=<NegBackward>)\n",
            "tensor(0.6246, grad_fn=<NegBackward>)\n",
            "tensor(0.3684, grad_fn=<NegBackward>)\n",
            "tensor(0.4729, grad_fn=<NegBackward>)\n",
            "tensor(0.1308, grad_fn=<NegBackward>)\n",
            "tensor(0.1426, grad_fn=<NegBackward>)\n",
            "tensor(0.2604, grad_fn=<NegBackward>)\n",
            "tensor(0.1145, grad_fn=<NegBackward>)\n",
            "tensor(0.4334, grad_fn=<NegBackward>)\n",
            "tensor(0.0913, grad_fn=<NegBackward>)\n",
            "tensor(0.2167, grad_fn=<NegBackward>)\n",
            "tensor(0.2398, grad_fn=<NegBackward>)\n",
            "tensor(0.2853, grad_fn=<NegBackward>)\n",
            "tensor(0.1834, grad_fn=<NegBackward>)\n",
            "tensor(0.2178, grad_fn=<NegBackward>)\n",
            "tensor(0.2843, grad_fn=<NegBackward>)\n",
            "tensor(0.4220, grad_fn=<NegBackward>)\n",
            "tensor(0.3058, grad_fn=<NegBackward>)\n",
            "tensor(0.2821, grad_fn=<NegBackward>)\n",
            "tensor(0.4076, grad_fn=<NegBackward>)\n",
            "tensor(0.1448, grad_fn=<NegBackward>)\n",
            "tensor(0.6190, grad_fn=<NegBackward>)\n",
            "tensor(0.2034, grad_fn=<NegBackward>)\n",
            "tensor(0.3634, grad_fn=<NegBackward>)\n",
            "tensor(0.3178, grad_fn=<NegBackward>)\n",
            "tensor(0.1698, grad_fn=<NegBackward>)\n",
            "tensor(0.3832, grad_fn=<NegBackward>)\n",
            "tensor(0.4420, grad_fn=<NegBackward>)\n",
            "tensor(0.1872, grad_fn=<NegBackward>)\n",
            "tensor(0.2798, grad_fn=<NegBackward>)\n",
            "tensor(0.1091, grad_fn=<NegBackward>)\n",
            "tensor(0.1175, grad_fn=<NegBackward>)\n",
            "tensor(0.1858, grad_fn=<NegBackward>)\n",
            "tensor(0.5959, grad_fn=<NegBackward>)\n",
            "tensor(0.2146, grad_fn=<NegBackward>)\n",
            "tensor(0.1542, grad_fn=<NegBackward>)\n",
            "tensor(0.2851, grad_fn=<NegBackward>)\n",
            "tensor(0.2008, grad_fn=<NegBackward>)\n",
            "tensor(0.2911, grad_fn=<NegBackward>)\n",
            "tensor(0.1611, grad_fn=<NegBackward>)\n",
            "tensor(0.1643, grad_fn=<NegBackward>)\n",
            "tensor(0.2231, grad_fn=<NegBackward>)\n",
            "tensor(0.5680, grad_fn=<NegBackward>)\n",
            "tensor(0.6560, grad_fn=<NegBackward>)\n",
            "tensor(0.4157, grad_fn=<NegBackward>)\n",
            "tensor(0.2258, grad_fn=<NegBackward>)\n",
            "tensor(0.3974, grad_fn=<NegBackward>)\n",
            "tensor(0.2444, grad_fn=<NegBackward>)\n",
            "tensor(0.2010, grad_fn=<NegBackward>)\n",
            "tensor(0.1096, grad_fn=<NegBackward>)\n",
            "tensor(0.2779, grad_fn=<NegBackward>)\n",
            "tensor(0.6587, grad_fn=<NegBackward>)\n",
            "tensor(0.5661, grad_fn=<NegBackward>)\n",
            "tensor(0.5487, grad_fn=<NegBackward>)\n",
            "tensor(0.2654, grad_fn=<NegBackward>)\n",
            "tensor(0.2027, grad_fn=<NegBackward>)\n",
            "tensor(0.3165, grad_fn=<NegBackward>)\n",
            "tensor(0.6258, grad_fn=<NegBackward>)\n",
            "tensor(0.2043, grad_fn=<NegBackward>)\n",
            "tensor(0.3102, grad_fn=<NegBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-fbim0tKB7D",
        "colab_type": "text"
      },
      "source": [
        "That's it: we've created and trained a minimal neural network (in this case, a\n",
        "logistic regression, since we have no hidden layers) entirely from scratch!\n",
        "\n",
        "Let's check the loss and accuracy and compare those to what we got\n",
        "earlier. We expect that the loss will have decreased and accuracy to\n",
        "have increased, and they have.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ0d4PcYKB7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "19b00e14-c65c-467f-a771-62a94b709a85"
      },
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0818, grad_fn=<NegBackward>) tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGu9tbV6KB7K",
        "colab_type": "text"
      },
      "source": [
        "Using torch.nn.functional\n",
        "------------------------------\n",
        "\n",
        "We will now refactor our code, so that it does the same thing as before, only\n",
        "we'll start taking advantage of PyTorch's ``nn`` classes to make it more concise\n",
        "and flexible. At each step from here, we should be making our code one or more\n",
        "of: shorter, more understandable, and/or more flexible.\n",
        "\n",
        "The first and easiest step is to make our code shorter by replacing our\n",
        "hand-written activation and loss functions with those from ``torch.nn.functional``\n",
        "(which is generally imported into the namespace ``F`` by convention). This module\n",
        "contains all the functions in the ``torch.nn`` library (whereas other parts of the\n",
        "library contain classes). As well as a wide range of loss and activation\n",
        "functions, you'll also find here some convenient functions for creating neural\n",
        "nets, such as pooling functions. (There are also functions for doing convolutions,\n",
        "linear layers, etc, but as we'll see, these are usually better handled using\n",
        "other parts of the library.)\n",
        "\n",
        "If you're using negative log likelihood loss and log softmax activation,\n",
        "then Pytorch provides a single function ``F.cross_entropy`` that combines\n",
        "the two. So we can even remove the activation function from our model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D97Dgg8cKB7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "def model(xb):\n",
        "  print(xb.shape)\n",
        "  print(weights.shape)\n",
        "  print(bias.shape)\n",
        "  return xb @ weights + bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LBNSlgFKB7P",
        "colab_type": "text"
      },
      "source": [
        "Note that we no longer call ``log_softmax`` in the ``model`` function. Let's\n",
        "confirm that our loss and accuracy are the same as before:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_clY2uyXKB7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "45166bbf-4a25-4400-83c9-8ef014281eac"
      },
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 784])\n",
            "torch.Size([784, 10])\n",
            "torch.Size([10])\n",
            "torch.Size([16, 784])\n",
            "torch.Size([784, 10])\n",
            "torch.Size([10])\n",
            "tensor(0.0818, grad_fn=<NllLossBackward>) tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HyGZJf8KB7V",
        "colab_type": "text"
      },
      "source": [
        "Refactor using nn.Module\n",
        "-----------------------------\n",
        "Next up, we'll use ``nn.Module`` and ``nn.Parameter``, for a clearer and more\n",
        "concise training loop. We subclass ``nn.Module`` (which itself is a class and\n",
        "able to keep track of state).  In this case, we want to _create a class that\n",
        "holds our weights, bias, and method for the forward step_ .  ``nn.Module`` has a\n",
        "number of attributes and methods (such as ``.parameters()`` and ``.zero_grad()``)\n",
        "which we will be using.\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``nn.Module`` (uppercase M) is a PyTorch specific concept, and is a\n",
        "   class we'll be using a lot. ``nn.Module`` is not to be confused with the Python\n",
        "   concept of a (lowercase ``m``) `module <https://docs.python.org/3/tutorial/modules.html>`_,\n",
        "   which is a file of Python code that can be imported.</p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2_5ybTxKB7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class Mnist_Logistic(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
        "    self.bias = nn.Parameter(torch.zeros(10))\n",
        "  \n",
        "  def forward(self, xb):\n",
        "    return xb @ self.weights + self.bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxlD0SH7KB7f",
        "colab_type": "text"
      },
      "source": [
        "Since we're now using an object instead of just using a function, we\n",
        "first have to instantiate our model:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjJutzTPKB7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Mnist_Logistic()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An0W-ALvKB7k",
        "colab_type": "text"
      },
      "source": [
        "Now we can calculate the loss in the same way as before. Note that\n",
        "``nn.Module`` objects are used as if they are functions (i.e they are\n",
        "*callable*), but behind the scenes Pytorch will call our ``forward``\n",
        "method automatically.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlzBBJOFKB7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c497399b-430d-4e35-a0b9-95af47c97203"
      },
      "source": [
        "print(loss_func(model(xb), yb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.4388, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JBPvGo6KB7r",
        "colab_type": "text"
      },
      "source": [
        "Previously for our training loop we had to update the values for each parameter\n",
        "by name, and manually zero out the grads for each parameter separately, like this:\n",
        "::\n",
        "  with torch.no_grad():\n",
        "      weights -= weights.grad * lr\n",
        "      bias -= bias.grad * lr\n",
        "      weights.grad.zero_()\n",
        "      bias.grad.zero_()\n",
        "\n",
        "\n",
        "Now we can take advantage of model.parameters() and model.zero_grad() (which\n",
        "are both defined by PyTorch for ``nn.Module``) to make those steps more concise\n",
        "and less prone to the error of forgetting some of our parameters, particularly\n",
        "if we had a more complicated model:\n",
        "::\n",
        "  with torch.no_grad():\n",
        "      for p in model.parameters(): p -= p.grad * lr\n",
        "      model.zero_grad()\n",
        "\n",
        "\n",
        "We'll wrap our little training loop in a ``fit`` function so we can run it\n",
        "again later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xCcqSTiKB7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for i in range(n // bs + 1):\n",
        "      start_i = i * bs\n",
        "      end_i = start_i + bs\n",
        "      xb = x_train[start_i : end_i]\n",
        "      yb = y_train[start_i : end_i]\n",
        "      pred = model(xb)\n",
        "      loss = loss_func(pred, yb)\n",
        "\n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "          p -= p.grad * lr\n",
        "        model.zero_grad() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3N6BXT3KB7w",
        "colab_type": "text"
      },
      "source": [
        "Let's double-check that our loss has gone down:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0uHYVr6KB7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0b388ede-320a-419a-fd1f-f1caa49f38af"
      },
      "source": [
        "print(loss_func(model(xb), yb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.4388, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZWv_pCmKB74",
        "colab_type": "text"
      },
      "source": [
        "Refactor using nn.Linear\n",
        "-------------------------\n",
        "\n",
        "We continue to refactor our code.  Instead of manually defining and\n",
        "initializing ``self.weights`` and ``self.bias``, and calculating ``xb  @\n",
        "self.weights + self.bias``, we will instead use the Pytorch class\n",
        "`nn.Linear <https://pytorch.org/docs/stable/nn.html#linear-layers>`_ for a\n",
        "linear layer, which does all that for us. Pytorch has many types of\n",
        "predefined layers that can greatly simplify our code, and often makes it\n",
        "faster too.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Makq3eW7KB76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mnist_Logistic(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.lin = nn.Linear(784, 10)\n",
        "  \n",
        "  def forward(self, xb):\n",
        "    return self.lin(xb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hez_hKsDKB8A",
        "colab_type": "text"
      },
      "source": [
        "We instantiate our model and calculate the loss in the same way as before:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anF4y7HFKB8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "dde5059c-c3d2-4480-80d8-7d179d89a361"
      },
      "source": [
        "model = Mnist_Logistic()\n",
        "print(loss_func(model(xb), yb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2896, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wEQbzcAKB8D",
        "colab_type": "text"
      },
      "source": [
        "We are still able to use our same ``fit`` method as before.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFJWqbwiKB8F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d0ced2fa-5e04-43c0-95ef-471518e1ac03"
      },
      "source": [
        "fit()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0813, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlujccCnKB8Q",
        "colab_type": "text"
      },
      "source": [
        "Refactor using optim\n",
        "------------------------------\n",
        "\n",
        "Pytorch also has a package with various optimization algorithms, ``torch.optim``.\n",
        "We can use the ``step`` method from our optimizer to take a forward step, instead\n",
        "of manually updating each parameter.\n",
        "\n",
        "This will let us replace our previous manually coded optimization step:\n",
        "::\n",
        "  with torch.no_grad():\n",
        "      for p in model.parameters(): p -= p.grad * lr\n",
        "      model.zero_grad()\n",
        "\n",
        "and instead use just:\n",
        "::\n",
        "  opt.step()\n",
        "  opt.zero_grad()\n",
        "\n",
        "(``optim.zero_grad()`` resets the gradient to 0 and we need to call it before\n",
        "computing the gradient for the next minibatch.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIVTRzTIKB8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIyZHemMKB8W",
        "colab_type": "text"
      },
      "source": [
        "We'll define a little function to create our model and optimizer so we\n",
        "can reuse it in the future.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw2d8xMZKB8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "afa5c991-d559-46f7-973d-5e623c6c36ef"
      },
      "source": [
        "def get_model():\n",
        "  model = Mnist_Logistic()\n",
        "  return model, optim.SGD(model.parameters(), lr)\n",
        "\n",
        "model, opt = get_model()\n",
        "print(loss_func(model(xb), yb))\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i in range((n - 1) // bs + 1):\n",
        "    start_i = i * bs\n",
        "    end_i = start_i + bs\n",
        "    xb = x_train[start_i:end_i]\n",
        "    yb = y_train[start_i:end_i]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "print(loss_func(model(xb), yb))    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2581, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0833, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvRcOSEVKB8c",
        "colab_type": "text"
      },
      "source": [
        "Refactor using Dataset\n",
        "------------------------------\n",
        "\n",
        "PyTorch has an abstract Dataset class.  A Dataset can be anything that has\n",
        "a ``__len__`` function (called by Python's standard ``len`` function) and\n",
        "a ``__getitem__`` function as a way of indexing into it.\n",
        "`This tutorial <https://pytorch.org/tutorials/beginner/data_loading_tutorial.html>`_\n",
        "walks through a nice example of creating a custom ``FacialLandmarkDataset`` class\n",
        "as a subclass of ``Dataset``.\n",
        "\n",
        "PyTorch's `TensorDataset <https://pytorch.org/docs/stable/_modules/torch/utils/data/dataset.html#TensorDataset>`_\n",
        "is a Dataset wrapping tensors. By defining a length and way of indexing,\n",
        "this also gives us a way to iterate, index, and slice along the first\n",
        "dimension of a tensor. This will make it easier to access both the\n",
        "independent and dependent variables in the same line as we train.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVf5w1BnKB8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO5y6ttcKB8h",
        "colab_type": "text"
      },
      "source": [
        "Both ``x_train`` and ``y_train`` can be combined in a single ``TensorDataset``,\n",
        "which will be easier to iterate over and slice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94JP2ggTKB8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c9a76e97-aff9-4d67-ddba-9d20f84b2999"
      },
      "source": [
        "train_ds = TensorDataset(x_train, y_train)\n",
        "print(len(train_ds[0][0]))\n",
        "print(train_ds[0][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "784\n",
            "tensor(5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hAd-87BKB8l",
        "colab_type": "text"
      },
      "source": [
        "Previously, we had to iterate through minibatches of x and y values separately:\n",
        "::\n",
        "    xb = x_train[start_i:end_i]\n",
        "    yb = y_train[start_i:end_i]\n",
        "\n",
        "\n",
        "Now, we can do these two steps together:\n",
        "::\n",
        "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j8dniPgKB8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "9963cc6a-8de8-4b59-e23a-3129a9803ea7"
      },
      "source": [
        "model , opt = get_model()\n",
        "print(loss_func(model(xb), yb))\n",
        "for epoch in range(epochs):\n",
        "  for i in range((n - 1 ) // bs + 1):\n",
        "    start_i = i * bs\n",
        "    xb, yb = train_ds[start_i : start_i + bs]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3492, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0818, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWUp1H6pKB8r",
        "colab_type": "text"
      },
      "source": [
        "Refactor using DataLoader\n",
        "------------------------------\n",
        "\n",
        "Pytorch's ``DataLoader`` is responsible for managing batches. You can\n",
        "create a ``DataLoader`` from any ``Dataset``. ``DataLoader`` makes it easier\n",
        "to iterate over batches. Rather than having to use ``train_ds[i*bs : i*bs+bs]``,\n",
        "the DataLoader gives us each minibatch automatically.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAZf_EleKB8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size = bs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJXxzR4DKB8w",
        "colab_type": "text"
      },
      "source": [
        "Previously, our loop iterated over batches (xb, yb) like this:\n",
        "::\n",
        "      for i in range((n-1)//bs + 1):\n",
        "          xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "          pred = model(xb)\n",
        "\n",
        "Now, our loop is much cleaner, as (xb, yb) are loaded automatically from the data loader:\n",
        "::\n",
        "      for xb,yb in train_dl:\n",
        "          pred = model(xb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1bfXfF9KB8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "8594026b-dbe5-4cb6-f776-2273d425e0fb"
      },
      "source": [
        "model, opt = get_model()\n",
        "print(loss_func(model(xb), yb))\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for xb, yb in train_dl:\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.4754, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0822, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0fsu5KLKB8z",
        "colab_type": "text"
      },
      "source": [
        "Thanks to Pytorch's ``nn.Module``, ``nn.Parameter``, ``Dataset``, and ``DataLoader``,\n",
        "our training loop is now dramatically smaller and easier to understand. Let's\n",
        "now try to add the basic features necessary to create effecive models in practice.\n",
        "\n",
        "Add validation\n",
        "-----------------------\n",
        "\n",
        "In section 1, we were just trying to get a reasonable training loop set up for\n",
        "use on our training data.  In reality, you **always** should also have\n",
        "a `validation set <https://www.fast.ai/2017/11/13/validation-sets/>`_, in order\n",
        "to identify if you are overfitting.\n",
        "\n",
        "Shuffling the training data is\n",
        "`important <https://www.quora.com/Does-the-order-of-training-data-matter-when-training-neural-networks>`_\n",
        "to prevent correlation between batches and overfitting. On the other hand, the\n",
        "validation loss will be identical whether we shuffle the validation set or not.\n",
        "Since shuffling takes extra time, it makes no sense to shuffle the validation data.\n",
        "\n",
        "We'll use a batch size for the validation set that is twice as large as\n",
        "that for the training set. This is because the validation set does not\n",
        "need backpropagation and thus takes less memory (it doesn't need to\n",
        "store the gradients). We take advantage of this to use a larger batch\n",
        "size and compute the loss more quickly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPkP6EwNKB80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = TensorDataset(x_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size = bs, shuffle = True)\n",
        "\n",
        "valid_ds = TensorDataset(x_valid, y_valid)\n",
        "valid_dl = DataLoader(valid_ds, batch_size = bs * 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFkvlD8gOLoH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c517bb86-c175-4cfa-cc17-953b73722c44"
      },
      "source": [
        "print(x_valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ12G0SfKB82",
        "colab_type": "text"
      },
      "source": [
        "We will calculate and print the validation loss at the end of each epoch.\n",
        "\n",
        "(Note that we always call ``model.train()`` before training, and ``model.eval()``\n",
        "before inference, because these are used by layers such as ``nn.BatchNorm2d``\n",
        "and ``nn.Dropout`` to ensure appropriate behaviour for these different phases.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7FkYMvHM-ll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "630a356f-a564-4584-e16a-d72fc4131ff8"
      },
      "source": [
        "print(valid_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7fb53e8a1c18>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GDQDk2HKB83",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1edaa9bd-df5f-4508-f996-82361d99c562"
      },
      "source": [
        "model, opt = get_model()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  for xb, yb in train_dl:\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "  \n",
        "  model.eval()\n",
        "  valid_loss = 0\n",
        "  with torch.no_grad():\n",
        "    valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
        "  print (valid_loss/len(valid_dl))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.3147)\n",
            "tensor(0.3101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cORmCx4pKB86",
        "colab_type": "text"
      },
      "source": [
        "Create fit() and get_data()\n",
        "----------------------------------\n",
        "\n",
        "We'll now do a little refactoring of our own. Since we go through a similar\n",
        "process twice of calculating the loss for both the training set and the\n",
        "validation set, let's make that into its own function, ``loss_batch``, which\n",
        "computes the loss for one batch.\n",
        "\n",
        "We pass an optimizer in for the training set, and use it to perform\n",
        "backprop.  For the validation set, we don't pass an optimizer, so the\n",
        "method doesn't perform backprop.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdl9ZFSWKB86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
        "  loss = loss_func(model(xb), yb)\n",
        "\n",
        "  if opt is not None:\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "  \n",
        "  return loss.item(), len(xb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaBIZpCUKB8_",
        "colab_type": "text"
      },
      "source": [
        "``fit`` runs the necessary operations to train our model and compute the\n",
        "training and validation losses for each epoch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJP1iiODKB8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def fit(epochs, model, loss_func, train_dl, valid_dl, opt):\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for xb, yb in train_dl:\n",
        "      loss_batch(model, loss_func, xb, yb, opt)\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      losses, nums = zip(\n",
        "          *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
        "          )\n",
        "      #print(losses)\n",
        "      #print(nums)\n",
        "    val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "\n",
        "    print(val_loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nYJObijKB9C",
        "colab_type": "text"
      },
      "source": [
        "``get_data`` returns dataloaders for the training and validation sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgaMo4bYKB9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(train_ds, valid_ds, bs):\n",
        "  return (\n",
        "      DataLoader(train_ds, batch_size = bs, shuffle=True),\n",
        "      DataLoader(valid_ds, batch_size=bs * 2),\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx21dOkLKB9G",
        "colab_type": "text"
      },
      "source": [
        "Now, our whole process of obtaining the data loaders and fitting the\n",
        "model can be run in 3 lines of code:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qznOl8DKB9H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "3196495a-a94f-4b91-9b56-8446c9998354"
      },
      "source": [
        "%%time\n",
        "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
        "model, opt = get_model()\n",
        "fit(epochs, model, loss_func, train_dl, valid_dl, opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.31426576416492463\n",
            "0.2911227351546288\n",
            "CPU times: user 1.43 s, sys: 52.2 ms, total: 1.48 s\n",
            "Wall time: 1.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2_mcSm-KB9K",
        "colab_type": "text"
      },
      "source": [
        "You can use these basic 3 lines of code to train a wide variety of models.\n",
        "Let's see if we can use them to train a convolutional neural network (CNN)!\n",
        "\n",
        "Switch to CNN\n",
        "-------------\n",
        "\n",
        "We are now going to build our neural network with three convolutional layers.\n",
        "Because none of the functions in the previous section assume anything about\n",
        "the model form, we'll be able to use them to train a CNN without any modification.\n",
        "\n",
        "We will use Pytorch's predefined\n",
        "`Conv2d <https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d>`_ class\n",
        "as our convolutional layer. We define a CNN with 3 convolutional layers.\n",
        "Each convolution is followed by a ReLU.  At the end, we perform an\n",
        "average pooling.  (Note that ``view`` is PyTorch's version of numpy's\n",
        "``reshape``)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3xU67wxKB9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mnist_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
        "    self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
        "  \n",
        "  def forward(self, xb):\n",
        "    xb = xb.view(-1, 1, 28, 28)\n",
        "    xb = F.relu(self.conv1(xb))\n",
        "    xb = F.relu(self.conv2(xb))\n",
        "    xb = F.relu(self.conv3(xb))\n",
        "    xb = F.avg_pool2d(xb, 4)\n",
        "    return xb.view(-1, xb.size(1))\n",
        "\n",
        "lr = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cubuzl6BKB9U",
        "colab_type": "text"
      },
      "source": [
        "`Momentum <https://cs231n.github.io/neural-networks-3/#sgd>`_ is a variation on\n",
        "stochastic gradient descent that takes previous updates into account as well\n",
        "and generally leads to faster training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DV5h4-nKB9V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7e294f1a-4ada-40e8-a5dc-c4f20b683a2e"
      },
      "source": [
        "model = Mnist_CNN()\n",
        "opt = optim.SGD(model.parameters(), lr = lr, momentum=0.9)\n",
        "\n",
        "fit(epochs, model, loss_func, train_dl, valid_dl, opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.36068561000823973\n",
            "0.25512010154128073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn_r5JDYKB9a",
        "colab_type": "text"
      },
      "source": [
        "nn.Sequential\n",
        "------------------------\n",
        "\n",
        "``torch.nn`` has another handy class we can use to simply our code:\n",
        "`Sequential <https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential>`_ .\n",
        "A ``Sequential`` object runs each of the modules contained within it, in a\n",
        "sequential manner. This is a simpler way of writing our neural network.\n",
        "\n",
        "To take advantage of this, we need to be able to easily define a\n",
        "**custom layer** from a given function.  For instance, PyTorch doesn't\n",
        "have a `view` layer, and we need to create one for our network. ``Lambda``\n",
        "will create a layer that we can then use when defining a network with\n",
        "``Sequential``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNQzXRPaKB9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lambda(nn.Module):\n",
        "  def __init__(self, func):\n",
        "    super().__init__()\n",
        "    self.func = func\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.func(x)\n",
        "\n",
        "def preprocess(x):\n",
        "  return x.view(-1, 1, 28, 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSFNNIO_KB9j",
        "colab_type": "text"
      },
      "source": [
        "The model created with ``Sequential`` is simply:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nup5iIlZKB9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "9a808e06-3605-4e6b-e33b-ec1ead5a5416"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    Lambda(preprocess),\n",
        "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
        "    nn.AvgPool2d(4),\n",
        "    Lambda(lambda x: x.view(x.size(0), -1))\n",
        ")\n",
        "\n",
        "opt = optim.SGD(model.parameters(), lr = lr, momentum=0.9)\n",
        "epochs = 2\n",
        "fit(epochs, model, loss_func, train_dl, valid_dl, opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5330254623889923\n",
            "0.38945050916671753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TIpi6BYKB9n",
        "colab_type": "text"
      },
      "source": [
        "Wrapping DataLoader\n",
        "-----------------------------\n",
        "\n",
        "Our CNN is fairly concise, but it only works with MNIST, because:\n",
        " - It assumes the input is a 28\\*28 long vector\n",
        " - It assumes that the final CNN grid size is 4\\*4 (since that's the average\n",
        "pooling kernel size we used)\n",
        "\n",
        "Let's get rid of these two assumptions, so our model works with any 2d\n",
        "single channel image. First, we can remove the initial Lambda layer but\n",
        "moving the data preprocessing into a generator:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meT744NaKB9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(x, y):\n",
        "  return x.view(-1, 1, 28, 28), y\n",
        "\n",
        "class WrappedDataLoader:\n",
        "  def __init__(self, dl, func):\n",
        "    self.dl = dl\n",
        "    self.func = func\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dl)\n",
        "  \n",
        "  def __iter__(self):\n",
        "    batches = iter(self.dl)\n",
        "    for b in batches:\n",
        "      yield (self.func(*b))\n",
        "\n",
        "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
        "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
        "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtPmE7nHKB9s",
        "colab_type": "text"
      },
      "source": [
        "Next, we can replace ``nn.AvgPool2d`` with ``nn.AdaptiveAvgPool2d``, which\n",
        "allows us to define the size of the *output* tensor we want, rather than\n",
        "the *input* tensor we have. As a result, our model will work with any\n",
        "size input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6NmE_fIKB9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AvgPool2d(1),\n",
        "    Lambda(lambda x:x.view(x.size(0), -1))\n",
        ")\n",
        "\n",
        "opt = optim.SGD(model.parameters(), lr = lr, momentum=0.9)\n",
        "#opt = optim.Adam(model.parameters())\n",
        "#fit(epochs, model, loss_func, train_dl, valid_dl, opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_469qjF0KB9y",
        "colab_type": "text"
      },
      "source": [
        "Let's try it out:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcK_fW6wKB9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "45516c88-211a-4fea-ffe3-e297f98360ac"
      },
      "source": [
        "fit(epochs, model, loss_func, train_dl, valid_dl, opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6224208158493043\n",
            "1.520626256942749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4RI88O7KB91",
        "colab_type": "text"
      },
      "source": [
        "Using your GPU\n",
        "---------------\n",
        "\n",
        "If you're lucky enough to have access to a CUDA-capable GPU (you can\n",
        "rent one for about $0.50/hour from most cloud providers) you can\n",
        "use it to speed up your code. First check that your GPU is working in\n",
        "Pytorch:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZvN4FFCKB92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1790336d-6fd0-4fd0-b769-79345c89dca3"
      },
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKiu-vulKB95",
        "colab_type": "text"
      },
      "source": [
        "And then create a device object for it:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhimRmSpKB95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghueLwBNKB-A",
        "colab_type": "text"
      },
      "source": [
        "Let's update ``preprocess`` to move batches to the GPU:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01H10FVSKB-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(x, y):\n",
        "  return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\n",
        "\n",
        "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
        "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
        "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7yhYauvKB-D",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can move our model to the GPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htmgi8-2KB-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to(dev)\n",
        "\n",
        "opt = optim.SGD(model.parameters(), lr = lr, momentum = 0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmA4nGqoKB-I",
        "colab_type": "text"
      },
      "source": [
        "You should find it runs faster now:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO6al_zBKB-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1296335d-f69f-464f-b764-36468b1bce93"
      },
      "source": [
        "fit(epochs, model, loss_func, train_dl, valid_dl, opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5207865436553956\n",
            "1.415876382446289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__CYqQrVKB-K",
        "colab_type": "text"
      },
      "source": [
        "Closing thoughts\n",
        "-----------------\n",
        "\n",
        "We now have a general data pipeline and training loop which you can use for\n",
        "training many types of models using Pytorch. To see how simple training a model\n",
        "can now be, take a look at the `mnist_sample` sample notebook.\n",
        "\n",
        "Of course, there are many things you'll want to add, such as data augmentation,\n",
        "hyperparameter tuning, monitoring training, transfer learning, and so forth.\n",
        "These features are available in the fastai library, which has been developed\n",
        "using the same design approach shown in this tutorial, providing a natural\n",
        "next step for practitioners looking to take their models further.\n",
        "\n",
        "We promised at the start of this tutorial we'd explain through example each of\n",
        "``torch.nn``, ``torch.optim``, ``Dataset``, and ``DataLoader``. So let's summarize\n",
        "what we've seen:\n",
        "\n",
        " - **torch.nn**\n",
        "\n",
        "   + ``Module``: creates a callable which behaves like a function, but can also\n",
        "     contain state(such as neural net layer weights). It knows what ``Parameter`` (s) it\n",
        "     contains and can zero all their gradients, loop through them for weight updates, etc.\n",
        "   + ``Parameter``: a wrapper for a tensor that tells a ``Module`` that it has weights\n",
        "     that need updating during backprop. Only tensors with the `requires_grad` attribute set are updated\n",
        "   + ``functional``: a module(usually imported into the ``F`` namespace by convention)\n",
        "     which contains activation functions, loss functions, etc, as well as non-stateful\n",
        "     versions of layers such as convolutional and linear layers.\n",
        " - ``torch.optim``: Contains optimizers such as ``SGD``, which update the weights\n",
        "   of ``Parameter`` during the backward step\n",
        " - ``Dataset``: An abstract interface of objects with a ``__len__`` and a ``__getitem__``,\n",
        "   including classes provided with Pytorch such as ``TensorDataset``\n",
        " - ``DataLoader``: Takes any ``Dataset`` and creates an iterator which returns batches of data.\n",
        "\n"
      ]
    }
  ]
}